{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gxaHrzqci9G",
        "outputId": "c6d21846-28ee-4a02-e7f6-07d3db7da789"
      },
      "source": [
        "!pip install torch\n",
        "!pip install bitsandbytes\n",
        "!pip install datasets==2.13.1\n",
        "!pip install scipy\n",
        "!pip install git+https://github.com/huggingface/accelerate.git\n",
        "!pip install git+https://github.com/huggingface/transformers.git\n",
        "!pip install git+https://github.com/huggingface/peft.git\n",
        "!pip install git+https://github.com/lvwerra/trl.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.8.61)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: bitsandbytes in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.45.3)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from bitsandbytes) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (1.13.3)\n",
            "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3,>=2.0->bitsandbytes) (12.8.61)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Collecting datasets==2.13.1\n",
            "  Using cached datasets-2.13.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==2.13.1) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==2.13.1) (19.0.1)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==2.13.1) (0.3.6)\n",
            "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==2.13.1) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==2.13.1) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==2.13.1) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==2.13.1) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==2.13.1) (0.70.14)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fsspec[http]>=2021.11.1->datasets==2.13.1) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==2.13.1) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==2.13.1) (0.29.1)\n",
            "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==2.13.1) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==2.13.1) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets==2.13.1) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets==2.13.1) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets==2.13.1) (5.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets==2.13.1) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets==2.13.1) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets==2.13.1) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets==2.13.1) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets==2.13.1) (1.18.3)\n",
            "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets==2.13.1) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets==2.13.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.13.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.13.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.13.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.13.1) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets==2.13.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets==2.13.1) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets==2.13.1) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.13.1) (1.17.0)\n",
            "Using cached datasets-2.13.1-py3-none-any.whl (486 kB)\n",
            "Installing collected packages: datasets\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 3.3.2\n",
            "    Uninstalling datasets-3.3.2:\n",
            "      Successfully uninstalled datasets-3.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "trl 0.16.0.dev0 requires datasets>=2.21.0, but you have datasets 2.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.13.1\n",
            "Requirement already satisfied: scipy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scipy) (1.26.4)\n",
            "Collecting git+https://github.com/huggingface/accelerate.git\n",
            "  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-j2ml5ko1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-j2ml5ko1\n",
            "\n",
            "  Resolved https://github.com/huggingface/accelerate.git to commit 90f81986b9014c146d4971531ef8b10d5816233a\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: numpy<3.0.0,>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate==1.4.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate==1.4.0.dev0) (24.2)\n",
            "Requirement already satisfied: psutil in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate==1.4.0.dev0) (6.1.1)\n",
            "Requirement already satisfied: pyyaml in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate==1.4.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate==1.4.0.dev0) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate==1.4.0.dev0) (0.29.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate==1.4.0.dev0) (0.5.2)\n",
            "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate==1.4.0.dev0) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate==1.4.0.dev0) (2024.12.0)\n",
            "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate==1.4.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate==1.4.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate==1.4.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->accelerate==1.4.0.dev0) (12.8.61)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate==1.4.0.dev0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.4.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.4.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.4.0.dev0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.4.0.dev0) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch>=2.0.0->accelerate==1.4.0.dev0) (1.3.0)\n",
            "Collecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-sdder77s\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-sdder77s\n",
            "\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 222505c7e4d08da9095d12ddb72fb653f4b6da33\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.50.0.dev0) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.50.0.dev0) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.50.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.50.0.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.50.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.50.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.50.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.50.0.dev0) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.50.0.dev0) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.50.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.0.dev0) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers==4.50.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers==4.50.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers==4.50.0.dev0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers==4.50.0.dev0) (2025.1.31)\n",
            "Collecting git+https://github.com/huggingface/peft.git\n",
            "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-pqzjjefl\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-pqzjjefl\n",
            "\n",
            "  Resolved https://github.com/huggingface/peft.git to commit f51203f3e4d8b3856596d3296dae7180f15910c1\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft==0.14.1.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft==0.14.1.dev0) (24.2)\n",
            "Requirement already satisfied: psutil in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft==0.14.1.dev0) (6.1.1)\n",
            "Requirement already satisfied: pyyaml in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft==0.14.1.dev0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft==0.14.1.dev0) (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft==0.14.1.dev0) (4.50.0.dev0)\n",
            "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft==0.14.1.dev0) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft==0.14.1.dev0) (1.4.0.dev0)\n",
            "Requirement already satisfied: safetensors in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft==0.14.1.dev0) (0.5.2)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft==0.14.1.dev0) (0.29.1)\n",
            "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.14.1.dev0) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.14.1.dev0) (2024.12.0)\n",
            "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.14.1.dev0) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.14.1.dev0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.14.1.dev0) (12.8.61)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers->peft==0.14.1.dev0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers->peft==0.14.1.dev0) (0.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.14.1.dev0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.14.1.dev0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.14.1.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.14.1.dev0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.14.1.dev0) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.14.1.dev0) (1.3.0)\n",
            "Collecting git+https://github.com/lvwerra/trl.git\n",
            "  Cloning https://github.com/lvwerra/trl.git to /tmp/pip-req-build-ucymhh0y\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/lvwerra/trl.git /tmp/pip-req-build-ucymhh0y\n",
            "\n",
            "  Resolved https://github.com/lvwerra/trl.git to commit ac327d5e84b54c4bc3c0ffc23c7d582a99d4028e\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: accelerate>=0.34.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from trl==0.16.0.dev0) (1.4.0.dev0)\n",
            "Collecting datasets>=2.21.0 (from trl==0.16.0.dev0)\n",
            "  Using cached datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: rich in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from trl==0.16.0.dev0) (13.9.4)\n",
            "Requirement already satisfied: transformers>=4.46.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from trl==0.16.0.dev0) (4.50.0.dev0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate>=0.34.0->trl==0.16.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate>=0.34.0->trl==0.16.0.dev0) (24.2)\n",
            "Requirement already satisfied: psutil in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate>=0.34.0->trl==0.16.0.dev0) (6.1.1)\n",
            "Requirement already satisfied: pyyaml in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate>=0.34.0->trl==0.16.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate>=0.34.0->trl==0.16.0.dev0) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate>=0.34.0->trl==0.16.0.dev0) (0.29.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate>=0.34.0->trl==0.16.0.dev0) (0.5.2)\n",
            "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.21.0->trl==0.16.0.dev0) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.21.0->trl==0.16.0.dev0) (19.0.1)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.21.0->trl==0.16.0.dev0) (0.3.6)\n",
            "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.21.0->trl==0.16.0.dev0) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.21.0->trl==0.16.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.21.0->trl==0.16.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.21.0->trl==0.16.0.dev0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.21.0->trl==0.16.0.dev0) (0.70.14)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.21.0->trl==0.16.0.dev0) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.21.0->trl==0.16.0.dev0) (3.11.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers>=4.46.0->trl==0.16.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers>=4.46.0->trl==0.16.0.dev0) (0.21.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich->trl==0.16.0.dev0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich->trl==0.16.0.dev0) (2.19.1)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich->trl==0.16.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl==0.16.0.dev0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl==0.16.0.dev0) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl==0.16.0.dev0) (5.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl==0.16.0.dev0) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl==0.16.0.dev0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl==0.16.0.dev0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl==0.16.0.dev0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl==0.16.0.dev0) (1.18.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->trl==0.16.0.dev0) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.16.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.16.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.16.0.dev0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.16.0.dev0) (2025.1.31)\n",
            "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (12.8.61)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets>=2.21.0->trl==0.16.0.dev0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets>=2.21.0->trl==0.16.0.dev0) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets>=2.21.0->trl==0.16.0.dev0) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.21.0->trl==0.16.0.dev0) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (1.3.0)\n",
            "Using cached datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "Installing collected packages: datasets\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.13.1\n",
            "    Uninstalling datasets-2.13.1:\n",
            "      Successfully uninstalled datasets-2.13.1\n",
            "Successfully installed datasets-3.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install bitsandbytes\n",
        "!pip install datasets==2.13.1\n",
        "!pip install scipy\n",
        "!pip install git+https://github.com/huggingface/accelerate.git\n",
        "!pip install git+https://github.com/huggingface/transformers.git\n",
        "!pip install git+https://github.com/huggingface/peft.git\n",
        "!pip install git+https://github.com/lvwerra/trl.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-uqF2vLEeDRD"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import bitsandbytes as bnb\n",
        "from datasets import load_dataset\n",
        "from functools import partial\n",
        "import os\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, AutoPeftModelForCausalLM\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed, Trainer, TrainingArguments, BitsAndBytesConfig,DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7xYV7zTgpQjq"
      },
      "outputs": [],
      "source": [
        "seed=42\n",
        "set_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5F4-4vbeZGA",
        "outputId": "c8cc188e-f472-423b-e512-090cd33dbbc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bitsandbytes in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.45.3)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from bitsandbytes) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (1.13.3)\n",
            "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3,>=2.0->bitsandbytes) (12.8.61)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch<3,>=2.0->bitsandbytes) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FdRiSeOXeDVi"
      },
      "outputs": [],
      "source": [
        "def load_model(model_name, bnb_config):\n",
        "    n_gpus = torch.cuda.device_count()\n",
        "    max_memory = f'{40960}MB'\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\", # dispatch efficiently the model on the available ressources\n",
        "        max_memory = {i: max_memory for i in range(n_gpus)},\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)\n",
        "\n",
        "    # Needed for LLaMA tokenizer\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    return model, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a7e0f7872bf640f88334dbbf0fb9cb4a",
            "7de1abc17a90492d8198821848627f74",
            "7ce437ccd7fa4eb78ba1c7f49983bb92",
            "9d489b023b214eec8d97e5387b521199",
            "98d5e61919e54f578f2dc4023335c5cb",
            "75d04fbf74d143ebb62efb889ecb0995",
            "3edb862a93a74509a393fa2d1bc81745",
            "3ad3a3a5b67348cd93ff94d6363ada9d",
            "6be94c113df142eeaf65577ffa14d302",
            "105423f09e104b469b66f5a920ab224d",
            "17997cc9291c4b958e89f107705c5eb3"
          ]
        },
        "id": "K5aG_18Aewsj",
        "outputId": "c1cf3191-2373-45aa-b432-3e0d97e2456d"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files=\"output_cleaned_fixed.jsonl\",split=\"train\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeV5TG4Uew1G",
        "outputId": "ad6518de-7758-4b11-d320-9606fdd7b663"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of prompts: 1898\n",
            "Column names are: ['instruction', 'context', 'response', 'category']\n"
          ]
        }
      ],
      "source": [
        "print(f'Number of prompts: {len(dataset)}')\n",
        "print(f'Column names are: {dataset.column_names}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "p-vrx1lhew77"
      },
      "outputs": [],
      "source": [
        "def create_prompt_formats(sample):\n",
        "    \"\"\"\n",
        "    Format various fields of the sample ('instruction', 'context', 'response')\n",
        "    Then concatenate them using two newline characters\n",
        "    :param sample: Sample dictionnary\n",
        "    \"\"\"\n",
        "\n",
        "    INTRO_BLURB = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
        "    INSTRUCTION_KEY = \"### Instruction:\"\n",
        "    INPUT_KEY = \"Input:\"\n",
        "    RESPONSE_KEY = \"### Response:\"\n",
        "    END_KEY = \"### End\"\n",
        "\n",
        "    blurb = f\"{INTRO_BLURB}\"\n",
        "    instruction = f\"{INSTRUCTION_KEY}\\n{sample['instruction']}\"\n",
        "    input_context = f\"{INPUT_KEY}\\n{sample['context']}\" if sample[\"context\"] else None\n",
        "    response = f\"{RESPONSE_KEY}\\n{sample['response']}\"\n",
        "    end = f\"{END_KEY}\"\n",
        "\n",
        "    parts = [part for part in [blurb, instruction, input_context, response, end] if part]\n",
        "\n",
        "    formatted_prompt = \"\\n\\n\".join(parts)\n",
        "\n",
        "    sample[\"text\"] = formatted_prompt\n",
        "\n",
        "    return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "n-4tJR26li12"
      },
      "outputs": [],
      "source": [
        "def get_max_length(model):\n",
        "    conf = model.config\n",
        "    max_length = None\n",
        "    for length_setting in [\"n_positions\", \"max_position_embeddings\", \"seq_length\"]:\n",
        "        max_length = getattr(model.config, length_setting, None)\n",
        "        if max_length:\n",
        "            print(f\"Found max lenth: {max_length}\")\n",
        "            break\n",
        "    if not max_length:\n",
        "        max_length =8192\n",
        "        print(f\"Using default max length: {max_length}\")\n",
        "    return max_length\n",
        "\n",
        "\n",
        "def preprocess_batch(batch, tokenizer, max_length):\n",
        "    \"\"\"\n",
        "    Tokenizing a batch\n",
        "    \"\"\"\n",
        "    return tokenizer(\n",
        "        batch[\"text\"],\n",
        "        max_length=max_length,\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "\n",
        "# SOURCE https://github.com/databrickslabs/dolly/blob/master/training/trainer.py\n",
        "def preprocess_dataset(tokenizer: AutoTokenizer, max_length: int, seed, dataset: str):\n",
        "    \"\"\"Format & tokenize it so it is ready for training\n",
        "    :param tokenizer (AutoTokenizer): Model Tokenizer\n",
        "    :param max_length (int): Maximum number of tokens to emit from tokenizer\n",
        "    \"\"\"\n",
        "\n",
        "    # Add prompt to each sample\n",
        "    print(\"Preprocessing dataset...\")\n",
        "    dataset = dataset.map(create_prompt_formats)#, batched=True)\n",
        "\n",
        "    # Apply preprocessing to each batch of the dataset & and remove 'instruction', 'context', 'response', 'category' fields\n",
        "    _preprocessing_function = partial(preprocess_batch, max_length=max_length, tokenizer=tokenizer)\n",
        "    dataset = dataset.map(\n",
        "        _preprocessing_function,\n",
        "        batched=True,\n",
        "        remove_columns=[\"instruction\", \"context\", \"response\", \"text\", \"category\"],\n",
        "    )\n",
        "\n",
        "    # Filter out samples that have input_ids exceeding max_length\n",
        "    dataset = dataset.filter(lambda sample: len(sample[\"input_ids\"]) < max_length)\n",
        "\n",
        "    # Shuffle dataset\n",
        "    dataset = dataset.shuffle(seed=seed)\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "r7z1dO-jlwc2"
      },
      "outputs": [],
      "source": [
        "def create_bnb_config():\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    )\n",
        "\n",
        "    return bnb_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "rOrTAlARl3pe"
      },
      "outputs": [],
      "source": [
        "def create_peft_config(modules):\n",
        "    \"\"\"\n",
        "    Create Parameter-Efficient Fine-Tuning config for your model\n",
        "    :param modules: Names of the modules to apply Lora to\n",
        "    \"\"\"\n",
        "    config = LoraConfig(\n",
        "        r=16,  # dimension of the updated matrices\n",
        "        lora_alpha=64,  # parameter for scaling\n",
        "        target_modules=modules,\n",
        "        lora_dropout=0.1,  # dropout probability for layers\n",
        "        bias=\"none\",\n",
        "        task_type=\"CAUSAL_LM\",\n",
        "    )\n",
        "\n",
        "    return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "PocpefkimG96"
      },
      "outputs": [],
      "source": [
        "def find_all_linear_names(model):\n",
        "    cls = bnb.nn.Linear4bit #if args.bits == 4 else (bnb.nn.Linear8bitLt if args.bits == 8 else torch.nn.Linear)\n",
        "    lora_module_names = set()\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, cls):\n",
        "            names = name.split('.')\n",
        "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
        "\n",
        "    if 'lm_head' in lora_module_names:  # needed for 16-bit\n",
        "        lora_module_names.remove('lm_head')\n",
        "    return list(lora_module_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "fuBYyF9bmNjN"
      },
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model, use_4bit=False):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        num_params = param.numel()\n",
        "        # if using DS Zero 3 and the weights are initialized empty\n",
        "        if num_params == 0 and hasattr(param, \"ds_numel\"):\n",
        "            num_params = param.ds_numel\n",
        "\n",
        "        all_param += num_params\n",
        "        if param.requires_grad:\n",
        "            trainable_params += num_params\n",
        "    if use_4bit:\n",
        "        trainable_params /= 2\n",
        "    print(\n",
        "        f\"all params: {all_param:,d} || trainable params: {trainable_params:,d} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"HF_TOKEN\"] = \"Replace wih  your token\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "login(token=os.getenv(\"HF_TOKEN\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424,
          "referenced_widgets": [
            "5274e3c16d114f0ea50ccca2d76406f8",
            "27cad37233f44d59bf75463ab551899d",
            "3408a6c94eb84f85bd85817e66516bc2",
            "6838b3e2adac4f529358a43d9a8b7740",
            "c6f5164cbf0a48ff89857b3d7a92e73d",
            "d52c961e1a7f48ebb67eaa5b9bcc5300",
            "f606b15090b447a6b6fbd61481dd8624",
            "79e025fc8e6444c398bd632b56458cab",
            "622f56aa5cc84b6889107df01e6b30bf",
            "815c373fc8284224abf399b8b0099b20",
            "e58fa949ba2a43c88f26bf97b47231b1",
            "9a072d29996c44a9b5c323f09206a405",
            "f70e3c23129f4515a48ee1712f3da70b",
            "c4a971659af54d26b90756601fcf0e5d",
            "851adcdf8cad4e908532cd0b4a33297f",
            "bb5d180413914ff2b051d2bb4f838e10",
            "6cf4fdb1a8324b32a043044902955d7c",
            "d9695c00c7d442d38bb26325d974350d",
            "decf38b88f734a9f9ceb58ab42c7eed5",
            "daa350d8d4c14204813b4e4218e9cd5d",
            "4b55c63eca5a47d7bb8021350e95535f",
            "a016c37949844acea161cf325be0edec",
            "2a096308a7924d6b9b61a2535839f309",
            "2366ed8a1480413cb095436f13a67d4e",
            "a475e49f89cc4478966147d12b15e7e2",
            "e8d073df6f8742e18d2fd22d9ab3967a",
            "e22a05323e0740ef93cb39a3ee84ed9c",
            "5cf13ca9928b41edb5bbdc55aa8827bf",
            "4cb0fa6886c049b289ed10b32453b1cd",
            "6f632bc1d7644536a454ef1c471ea72a",
            "111ae0b8e63f472cb93f15d484d47489",
            "4dc7dc4eaf72438696873714f8340306",
            "a9b8128f66fe4aa9a90824b9328c72e8",
            "7b44a3cb7f7542b7894d7cffd678be13",
            "de41f1ce52404698b701a19643bacd1e",
            "fd17e394b34b48bfbfe74fc15b967e8a",
            "da2d0880d9bd479994381c32b3f33feb",
            "f1a4aca5f1ae40a08ab4e392cffcdf22",
            "82eb5bba126243ffa959d54580b157bb",
            "25bfac9a2c054bdf8d449b815c1e1b76",
            "95e3e5a5e25b43d8aa433f24ea37619a",
            "bf89f65111ea483f876b082d8cb82786",
            "366e3a590dbc43f082dc52855ff6ba9b",
            "40260f3b152d4fb6baab27715bf38d3e",
            "e2f5af3717f0403ba3011ed9a0c44df1",
            "d69bf5645de24de68131a00fd3b1ea3e",
            "78fad996692c47fe9731405fd0247ae2",
            "f5e95f158c984620880f152122228041",
            "74d0b880f9e04102ab38e95ce66a4886",
            "95e2441a15584cd9bbc951a3f35e8c66",
            "f2db6890a0224ee1be8271e7de0198b1",
            "1022ab469cd8457cbda4c3ba75938ef2",
            "09454937d0f34dae90863559dad242c6",
            "c85e0f0918c04f25ad7e0000690f0ddb",
            "2c8041c25f1d49ff965957cb471905d8",
            "5dd73d5e751b4d479b3449214a2c0d6f",
            "1c2e8439bb14496691c12418f1267d32",
            "ef86898a02f84071970030d7b1d54c1e",
            "54b82396fd0347818244611aaa816910",
            "d6d84ab8df6847ea931ca6c895aeaa82",
            "657254ed1061495d9eff75585e50e3a0",
            "c820ba86d9ce42f4ba1051c5ed0982d3",
            "08498f1924b24a56883204d3ac3462ce",
            "bf77e8d9ff6949f28587718c49b3a4dc",
            "c32a8c1174f74eb48e9250d93f35d321",
            "c5f9a31e342a426389bd97e4f485732a",
            "7fd24ef4645b40f38841668a6f52a4d8",
            "d19fb944aa734c1a9d978c7a8f8697c9",
            "183b2ed298f144d18cde7b68c1c7ef09",
            "c329802d6a904892b21875fa574b0af2",
            "a834087dc73444fd85ee32c1b5aae5e8",
            "5511ca8c1f8741b88c76c812a69f7b74",
            "76669936c01d455e86749c020b9c5f40",
            "9ced80a1efff4871b368bcdf2878ab7e",
            "f10f1b8aa5914ff4a5d5b20ba63c92d5",
            "fa7414aac0c544d9bcf91c9db571309b",
            "f8adbc24b704444e984a696173cc8ced",
            "45ddfa77ba844cdc9f6c3a2bd9f58c0c",
            "b9902700ef0e45a3968711d784553f40",
            "7115888a87c2489b9e57e413013f4088",
            "05fafc57d2df4b8eaf55c9c3c4c6ae68",
            "a016c67c66ba4dc09519dbc1444e63cd",
            "ebb71fdd59844154af88a5f7d06bcb39",
            "bbfa52a3a69542e2a6a76de7edb2f3dd",
            "1de3612e9cd0471a9d4b7a97d7f67382",
            "3f23a82e950a4ba9849644666eb1de44",
            "8235bece0b374394911b7cdcefdd6069",
            "c275e418600540d0889684476cbd7f10",
            "ca3c2ee25a1d4b07961b7b6e645b0924",
            "fe19b4c27da24b63a08d8e30dcc4f8c2",
            "4ec685ac30134eb9acf6608b2a5d48f6",
            "d443808e423b4010ba30615a8c3b8730",
            "e4f2e1ecf7b246559185ea9afa2bf96d",
            "b4a18682defd42e29ac036d754bf63c1",
            "b3ef3591e84743e292c0a1c9c0a5ea07",
            "1b6a32a861ba47aa8c2b0421d7446e38",
            "96c08135ed0a4074a9f7611b7025f93d",
            "dc17fe6575024facb15c05e157622b7e",
            "5d3d5c6c580d4b8a9ff54951c663db31",
            "c33c6a738f304b54abe4b00b81a426e2",
            "c83eb120c8ae4445934f862622f3658e",
            "f82defedb9a84395aaa0490e4cb2b39b",
            "6c7cc831d4b043eeb786daee5f06e570",
            "f88676cc6cdd41d78757bd44dd5fac4e",
            "105772994f384981944e6cd47bc454c0",
            "f0328557549c4f4aba843e630c8e37c2",
            "d2ec397860284fe2b77003aa0cc8ca08",
            "825760d4d3cc40fda33d6d263366b886",
            "e12ca76e414347adac47597d86d78129",
            "a82a861ee41744079a5d9fb3cc0e6b25",
            "d4ce4d8312a1482ab3f12b4402a2d614",
            "b30ed3332c514972b385c5096cab961f",
            "e1ab5a1d24b54fddaca57ca8b176f8d5",
            "2a6f2cc06b2e4817a17873da1f6340a6",
            "4a32550a19544b238fe4d629321a81ea",
            "34f616e54ec8488499586bbc7f34960b",
            "7f412a4c0e7444b09b06dca9cd897e97",
            "065716abe11c489ba9f99538d7f4aa92",
            "9664bb14307c4eb9b80de16d672c4f65",
            "5e3782e3683c49b7acf088922f9f7efe",
            "9d6d9f0acbf645a4af5c5d2f6cce730a"
          ]
        },
        "id": "SETyImk6mTgT",
        "outputId": "79256e8e-2978-429d-9153-4def27cbab4d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad8caef61fcb4bf5a6a45c16c7793189",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_name = \"google/gemma-2-2b-it\"\n",
        "\n",
        "bnb_config = create_bnb_config()\n",
        "\n",
        "model, tokenizer = load_model(model_name, bnb_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148,
          "referenced_widgets": [
            "6edcc0fd6ea2496cb208df9a0a16d06a",
            "d6d4ca1d68f846a6bc310a5f23adbccb",
            "bf8119cfb53546b0be17e9b06e973322",
            "4d0198ff6abb43beb9ddbd3ce9063d1f",
            "a00b20c75e8e4eef8ed06c624ec5509b",
            "3cb5750426cf42f4a405bcccf1e75c60",
            "8b6be3a7608743e19d4815dfbaf7d32e",
            "0569b998791d419a88aa1fb8236f7edf",
            "253d2ef1db514fec9ddc423f294e460b",
            "67e37c4608af4443adf51ca2dda763c3",
            "de8e236876ca4deb94f1e722c9cefaa6",
            "4d8f3e697d3f4cfd814cfda0890fa1f5",
            "20aa326f75aa4a76af3f64e2000faa11",
            "a5310ad5f3cf460485e4bc4a8f3ad845",
            "bd81385d5ba84c8fbeb39305c34f5785",
            "b9dd980e52cf48caba45a8d228de34ea",
            "0a8ed977bbc04adf9de698259ff04120",
            "9b117ebbcbc34926a60491037735848d",
            "74abbe6ca05349b8a29bdf76f0337dc6",
            "72ee8128268c4241a6f84ec4b2c32837",
            "821a39d28a2645a49288084b806e8779",
            "7414aebf6f0342dfaaa53e4d3dd45d98",
            "8dc128a5772943c498434ea6ec29dd24",
            "2d7e4da78dbf4138b68df674e83c3f0a",
            "0fb377025abe4cfcaae0b5b3fbef9c5f",
            "6d46d160a07348d9890581b8cfcc706d",
            "fb56b601efdb4904891d26a1d835051b",
            "cc6e43f233c6447a9b84f70925380a6f",
            "8e752803389342488471c92471e23c32",
            "6259c70435a843d0afcc4f8de6b62423",
            "8bdbee54e69641be8279af18db853969",
            "22d9952d76f54e4b98c000d983fa9c2b",
            "80eca95c72f14a8190520f6c19558b8c"
          ]
        },
        "id": "PPKAniQKm0Cn",
        "outputId": "f484494f-53da-482b-fcda-ad52baffe061"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found max lenth: 8192\n",
            "Preprocessing dataset...\n"
          ]
        }
      ],
      "source": [
        "max_length = get_max_length(model)\n",
        "\n",
        "dataset = preprocess_dataset(tokenizer, max_length, seed, dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Allocated Memory: 2.07 GB\n",
            "Cached Memory: 4.90 GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(f\"Allocated Memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
        "print(f\"Cached Memory: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "all params: 1,622,970,624 || trainable params: 20,766,720 || trainable%: 1.279549961835908\n",
            "torch.float32: 610832640 parameters, 37.64% of total\n",
            "torch.uint8: 1012137984 parameters, 62.36% of total\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "It is strongly recommended to train Gemma2 models with the `eager` attention implementation instead of `sdpa`. Use `eager` with `AutoModelForCausalLM.from_pretrained('<path-to-checkpoint>', attn_implementation='eager')`.\n",
            "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 1:56:39, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.446900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.329400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.282900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.257000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.231100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.199500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.182700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.182400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.148900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.164600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.230800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.186400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>1.148500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.125800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.120600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.128600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>1.106700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>1.107100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>1.088000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.076300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>1.090700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>1.096600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>1.094900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>1.110700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.050200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>1.047300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>1.038900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>1.012700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>1.030600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.002200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>1.028600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>1.023900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>1.009200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>1.017700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>1.031300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.970400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.980000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.992100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.964300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.965700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.989900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.939500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.973800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.973200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.993300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.985200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>1.003000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.944500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.947100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.985200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "***** train metrics *****\n",
            "  epoch                    =      4.2025\n",
            "  total_flos               = 185584124GF\n",
            "  train_loss               =      1.0807\n",
            "  train_runtime            =  1:56:53.94\n",
            "  train_samples_per_second =       1.141\n",
            "  train_steps_per_second   =       0.071\n",
            "{'train_runtime': 7013.9411, 'train_samples_per_second': 1.141, 'train_steps_per_second': 0.071, 'total_flos': 1.9926943684972646e+17, 'train_loss': 1.0807353668212891, 'epoch': 4.2025316455696204}\n",
            "Saving last checkpoint of the model...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "from peft import prepare_model_for_kbit_training, get_peft_model\n",
        "\n",
        "def train(model, tokenizer, dataset, output_dir):\n",
        "    # Enable gradient checkpointing to reduce memory usage during fine-tuning\n",
        "    model.gradient_checkpointing_enable()\n",
        "\n",
        "    # Prepare model for 8-bit training with PEFT\n",
        "    model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "    # Find all linear module names (LoRA layers)\n",
        "    modules = find_all_linear_names(model)\n",
        "\n",
        "    # Create PEFT config and wrap the model\n",
        "    peft_config = create_peft_config(modules)\n",
        "    model = get_peft_model(model, peft_config)\n",
        "\n",
        "    # Print percentage of trainable parameters\n",
        "    print_trainable_parameters(model)\n",
        "\n",
        "    # Setup training parameters with optimized settings\n",
        "    trainer = Trainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=1,  # Reduce batch size\n",
        "        gradient_accumulation_steps=16,  # Higher accumulation to compensate\n",
        "        bf16=True,  # Use bf16 instead of fp16 if supported\n",
        "        warmup_steps=5,\n",
        "        max_steps=500,  \n",
        "        logging_steps=10,  \n",
        "        output_dir=output_dir,\n",
        "        optim=\"paged_adamw_8bit\",  # More memory-efficient optimizer\n",
        "        save_strategy=\"epoch\",  # Save only per epoch\n",
        "        save_total_limit=1,  # Keep only last checkpoint\n",
        "    ),\n",
        "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        ")\n",
        "\n",
        "\n",
        "    # Disable caching to ensure training performance isn't hindered\n",
        "    model.config.use_cache = False\n",
        "\n",
        "    # Verify and print data types of model parameters before training\n",
        "    dtypes = {}\n",
        "    for name, param in model.named_parameters():\n",
        "        dtype = param.dtype\n",
        "        if dtype not in dtypes:\n",
        "            dtypes[dtype] = 0\n",
        "        dtypes[dtype] += param.numel()\n",
        "    total = sum(dtypes.values())\n",
        "    for dtype, count in dtypes.items():\n",
        "        print(f\"{dtype}: {count} parameters, {count / total:.2%} of total\")\n",
        "\n",
        "    # Launch training if conditions are met\n",
        "    print(\"Training...\")\n",
        "    train_result = trainer.train()\n",
        "    metrics = train_result.metrics\n",
        "\n",
        "    # Log and save metrics\n",
        "    trainer.log_metrics(\"train\", metrics)\n",
        "    trainer.save_metrics(\"train\", metrics)\n",
        "    trainer.save_state()\n",
        "\n",
        "    # Print final training metrics\n",
        "    print(metrics)\n",
        "\n",
        "    # Save the final model checkpoint\n",
        "    print(\"Saving last checkpoint of the model...\")\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    trainer.model.save_pretrained(output_dir)\n",
        "\n",
        "    # Free up CUDA memory\n",
        "    del model, trainer\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Define output directory for saving the model\n",
        "output_dir = \"resultstEST_2.0/llama2/final_checkpoint\"\n",
        "# Execute the training function\n",
        "train(model, tokenizer, dataset, output_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_dir = \"results/gemma2b/legal_summarization\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bb67afee2d14040b155dac126a684b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model successfully merged and saved at: /teamspace/studios/this_studio/results/final\n"
          ]
        }
      ],
      "source": [
        "from peft import AutoPeftModelForCausalLM\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Correct path where the fine-tuned model is stored\n",
        "output_dir = \"/teamspace/studios/this_studio/resultstEST_2.0/llama2/final_checkpoint\"\n",
        "\n",
        "# Load fine-tuned PEFT model with LoRA adapters\n",
        "model = AutoPeftModelForCausalLM.from_pretrained(output_dir, device_map=\"auto\", torch_dtype=\"auto\")\n",
        "\n",
        "# Merge LoRA into the base model (this removes the adapter)\n",
        "model = model.merge_and_unload()\n",
        "\n",
        "# Define the path to save the fully merged model\n",
        "merged_output_dir = \"/teamspace/studios/this_studio/results/final\"\n",
        "model.save_pretrained(merged_output_dir, safe_serialization=True)\n",
        "\n",
        "# Save tokenizer along with the merged model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b-it\")\n",
        "tokenizer.save_pretrained(merged_output_dir)\n",
        "\n",
        "print(\"✅ Model successfully merged and saved at:\", merged_output_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwnZUIDw14qF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfgOB0VCp9TQ",
        "outputId": "fc905c9d-d780-4e48-b56a-fc4588901e1a"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Can't find 'adapter_config.json' at 'results/gemma2b/legal_summarization'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/config.py:198\u001b[0m, in \u001b[0;36mPeftConfigMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 198\u001b[0m     config_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhf_hub_download_kwargs\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 106\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:154\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo_id\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m     )\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n",
            "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'results/gemma2b/legal_summarization'. Use `repo_type` argument if needed.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoPeftModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmerge_and_unload()\n\u001b[1;32m      4\u001b[0m output_merged_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/llama2/final_merged_checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/auto.py:82\u001b[0m, in \u001b[0;36m_BaseAutoPeftModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, adapter_name, is_trainable, config, revision, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_pretrained\u001b[39m(\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     76\u001b[0m ):\n\u001b[1;32m     77\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m    A wrapper around all the preprocessing steps a user needs to perform in order to load a PEFT model. The kwargs\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m    are passed along to `PeftConfig` that automatically takes care of filtering the kwargs of the Hub methods and\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m    the config object init.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m     peft_config \u001b[38;5;241m=\u001b[39m \u001b[43mPeftConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     base_model_path \u001b[38;5;241m=\u001b[39m peft_config\u001b[38;5;241m.\u001b[39mbase_model_name_or_path\n\u001b[1;32m     84\u001b[0m     base_model_revision \u001b[38;5;241m=\u001b[39m peft_config\u001b[38;5;241m.\u001b[39mrevision\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/config.py:202\u001b[0m, in \u001b[0;36mPeftConfigMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m         config_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[1;32m    199\u001b[0m             pretrained_model_name_or_path, CONFIG_NAME, subfolder\u001b[38;5;241m=\u001b[39msubfolder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhf_hub_download_kwargs\n\u001b[1;32m    200\u001b[0m         )\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m--> 202\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m at \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m    204\u001b[0m loaded_attributes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_json_file(config_file)\n\u001b[1;32m    205\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclass_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloaded_attributes}\n",
            "\u001b[0;31mValueError\u001b[0m: Can't find 'adapter_config.json' at 'results/gemma2b/legal_summarization'"
          ]
        }
      ],
      "source": [
        "'''model = AutoPeftModelForCausalLM.from_pretrained(output_dir, device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
        "model = model.merge_and_unload()\n",
        "\n",
        "output_merged_dir = \"results/llama2/final_merged_checkpoint\"\n",
        "os.makedirs(output_merged_dir, exist_ok=True)\n",
        "model.save_pretrained(output_merged_dir, safe_serialization=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.save_pretrained(output_merged_dir)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RepoUrl('https://huggingface.co/coderop12/Empowering_Legal_Summarization', endpoint='https://huggingface.co', repo_type='model', repo_id='coderop12/Empowering_Legal_Summarization')"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from huggingface_hub import HfApi\n",
        "\n",
        "# Initialize the Hugging Face API\n",
        "api = HfApi()\n",
        "\n",
        "# Create a new repo (replace with your desired repo name)\n",
        "repo_name = \"Empowering_Legal_Summarization\"  # Change this to your desired repo name\n",
        "api.create_repo(repo_name, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f676e56ec9794a419b10ae19e05a0b73",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/34.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1b5020daa2243f2a1c6d859398f232f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cef99492e0e04dc099d47dc7e6bc16f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/241M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7c4d833649b4dc8acdb39a9db75d22b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folder uploaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# 1. Make sure you have an up-to-date huggingface_hub:\n",
        "#    pip install --upgrade huggingface_hub\n",
        "\n",
        "from huggingface_hub import login, upload_folder\n",
        "\n",
        "# Log in to Hugging Face\n",
        "login(token=\"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\")  # Replace with your API token\n",
        "\n",
        "# Set the repository name and username\n",
        "repo_name = \"Empowering_Legal_Summarization\"  # The repo must already exist on your Hugging Face account\n",
        "repo_id = f\"coderop12/{repo_name}\"\n",
        "\n",
        "# Local folder you want to upload\n",
        "local_folder_path = r\"/teamspace/studios/this_studio/results/final\"\n",
        "\n",
        "# Upload the entire folder to the root of the repo\n",
        "upload_folder(\n",
        "    folder_path=local_folder_path,\n",
        "    repo_id=repo_id,\n",
        "    commit_message=\"Uploading the entire final_merged_checkpoint folder\"\n",
        ")\n",
        "\n",
        "print(\"Folder uploaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea2d187f00b9458b854cebb519e74583",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b626339171b04f229dad9fdfdd3b0409",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   3%|3         | 168M/4.99G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6ec3bb6cdb646ad9aee33d1b494d24a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/241M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "410bb0a63872495f8e5aacb03d72fc34",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8221f41a2c24ab6bffd843e68cc26b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/192 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model loaded successfully in eager mode.\n",
            "📄 Processing: converted_text.pdf\n",
            "⚠️ Error saving to Excel (No module named 'openpyxl'). Falling back to CSV...\n",
            "✅ Summaries saved to CSV instead: output_summaries_1.csv\n",
            "🎉 Processing complete!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import PyPDF2\n",
        "import pandas as pd\n",
        "import torch\n",
        "import re\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# ✅ Completely disable Torch Dynamo to prevent recompile errors\n",
        "import torch._dynamo\n",
        "torch._dynamo.config.suppress_errors = True  # Prevent crashing\n",
        "torch._dynamo.config.cache_size_limit = 0  # Disable cache\n",
        "torch._dynamo.config.verbose = False  # Reduce logging\n",
        "\n",
        "# ✅ Disable PyTorch compilation for models\n",
        "os.environ[\"TORCH_COMPILE\"] = \"0\"\n",
        "os.environ[\"TORCHDYNAMO_DISABLE\"] = \"1\"\n",
        "os.environ[\"TORCH_INDUCTOR_DISABLED\"] = \"1\"\n",
        "\n",
        "# Function to sanitize text by removing illegal characters\n",
        "def sanitize_text(text):\n",
        "    return re.sub(r'[\\x00-\\x1F\\x7F-\\x9F]', '', text)\n",
        "\n",
        "# Function to load the model and tokenizer and move the model to GPU\n",
        "def load_model_and_tokenizer(model_name):\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name, \n",
        "            torch_dtype=torch.float16,  # Load in fp16 for efficiency\n",
        "            device_map=\"auto\"  # Automatically use GPU if available\n",
        "        )\n",
        "\n",
        "        # 🚀 Ensure model runs in eager mode (no compilation)\n",
        "        if torch.cuda.is_available():\n",
        "            model.to(\"cuda\")  # Move model to GPU\n",
        "        print(\"✅ Model loaded successfully in eager mode.\")\n",
        "        return model, tokenizer\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading model/tokenizer: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Function to extract text from a PDF file\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text() or \"\"  # Ensure text is not None\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error extracting text from PDF {pdf_path}: {e}\")\n",
        "    return text.strip()\n",
        "\n",
        "# Function to generate a summary\n",
        "def generate_summary(input_text, model, tokenizer):\n",
        "    try:\n",
        "        prompt = (\n",
        "            \"Below is a legal document. Summarize its key points in a concise manner.\\n\\n\"\n",
        "            \"### Document:\\n{input_text}\\n\\n### Summary:\"\n",
        "        )\n",
        "\n",
        "        # Ensure input text is within 8192 token limit\n",
        "        input_str = prompt.format(input_text=input_text[:8192])\n",
        "\n",
        "        model_inputs = tokenizer(\n",
        "            input_str,\n",
        "            return_tensors='pt',\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=8192  # Set explicit max length\n",
        "        ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        summary_output = model.generate(\n",
        "            model_inputs.input_ids,\n",
        "            max_new_tokens=1024,\n",
        "            do_sample=True,  # Fix warning by enabling sampling\n",
        "            top_k=50,\n",
        "            top_p=0.95,\n",
        "            temperature=0.5\n",
        "        )\n",
        "\n",
        "        summary = tokenizer.decode(summary_output[0], skip_special_tokens=True)\n",
        "        return summary\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error generating summary: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model_name = \"coderop12/Empowering_Legal_Summarization\"  # Replace with your preferred causal LM model\n",
        "model, tokenizer = load_model_and_tokenizer(model_name)\n",
        "\n",
        "# ✅ Verify the casefile path exists before processing\n",
        "pdf_directory = \"casefile\"  # Your casefile directory\n",
        "\n",
        "if not os.path.exists(pdf_directory):\n",
        "    print(f\"❌ Error: The specified directory '{pdf_directory}' does not exist.\")\n",
        "    exit(1)  # Stop execution if the folder is missing\n",
        "\n",
        "if model is not None and tokenizer is not None:\n",
        "    output_data = []\n",
        "\n",
        "    # Process each PDF in the directory\n",
        "    for filename in os.listdir(pdf_directory):\n",
        "        if filename.endswith(\".pdf\"):\n",
        "            pdf_path = os.path.join(pdf_directory, filename)\n",
        "            print(f\"📄 Processing: {filename}\")\n",
        "            document_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "            if document_text:\n",
        "                sanitized_text = sanitize_text(document_text)\n",
        "                summary = generate_summary(sanitized_text, model, tokenizer)\n",
        "                sanitized_summary = sanitize_text(summary)\n",
        "                output_data.append({\"Filename\": filename, \"Summary\": sanitized_summary})\n",
        "            else:\n",
        "                print(f\"⚠️ Skipping {filename} - No extractable text found.\")\n",
        "\n",
        "    # Save results to Excel and CSV\n",
        "    df = pd.DataFrame(output_data)\n",
        "    output_excel_path = \"output_summaries_1.xlsx\"\n",
        "    output_csv_path = \"output_summaries_1.csv\"\n",
        "\n",
        "    try:\n",
        "        df.to_excel(output_excel_path, index=False)\n",
        "        print(f\"✅ Summaries saved to Excel: {output_excel_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error saving to Excel ({e}). Falling back to CSV...\")\n",
        "        df.to_csv(output_csv_path, index=False)\n",
        "        print(f\"✅ Summaries saved to CSV instead: {output_csv_path}\")\n",
        "\n",
        "    print(\"🎉 Processing complete!\")\n",
        "else:\n",
        "    print(\"❌ Failed to load model/tokenizer. Exiting.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "748de1e2bc9e4ebfa8119a6c3bfcddb3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model loaded successfully.\n",
            "📄 Processing: converted_text.pdf\n",
            "✅ Summaries saved to Excel: output_summaries_2_finetuned.xlsx\n",
            "🎉 Processing complete!\n"
          ]
        }
      ],
      "source": [
        "#Inference run 2\n",
        "import os\n",
        "import PyPDF2\n",
        "import pandas as pd\n",
        "import torch\n",
        "import re\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# ✅ Fully disable Torch Dynamo to prevent errors\n",
        "import torch._dynamo\n",
        "torch._dynamo.config.suppress_errors = True\n",
        "os.environ[\"TORCH_COMPILE\"] = \"0\"\n",
        "os.environ[\"TORCHDYNAMO_DISABLE\"] = \"1\"\n",
        "os.environ[\"TORCH_INDUCTOR_DISABLED\"] = \"1\"\n",
        "\n",
        "# Function to sanitize text by removing illegal characters\n",
        "def sanitize_text(text):\n",
        "    return re.sub(r'[\\x00-\\x1F\\x7F-\\x9F]', '', text)\n",
        "\n",
        "# Function to load the model and tokenizer and move the model to GPU\n",
        "def load_model_and_tokenizer(model_name):\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name, \n",
        "            torch_dtype=torch.float16,  # Load in fp16 for efficiency\n",
        "            device_map=\"auto\"  # Automatically use GPU if available\n",
        "        )\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            model.to(\"cuda\")\n",
        "        print(\"✅ Model loaded successfully.\")\n",
        "        return model, tokenizer\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading model/tokenizer: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Function to extract text from a PDF file\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text() or \"\"  # Ensure text is not None\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error extracting text from PDF {pdf_path}: {e}\")\n",
        "    return text.strip()\n",
        "\n",
        "# Function to generate a summary (FIXED)\n",
        "def generate_summary(input_text, model, tokenizer):\n",
        "    try:\n",
        "        prompt = (\n",
        "            \"Below is a legal document. Summarize its key points concisely.\\n\\n\"\n",
        "            \"### Document:\\n{input_text}\\n\\n### Summary:\"\n",
        "        )\n",
        "\n",
        "        input_str = prompt.format(input_text=input_text[:4096])  # Reduce input size\n",
        "\n",
        "        model_inputs = tokenizer(\n",
        "            input_str,\n",
        "            return_tensors='pt',\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=4096  # Reduce token count to prevent looping\n",
        "        ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        summary_output = model.generate(\n",
        "            model_inputs.input_ids,\n",
        "            max_new_tokens=256,  # Reduce summary length\n",
        "            do_sample=True,  # Enable sampling\n",
        "            top_k=40,  # Reduce likelihood of choosing most probable words\n",
        "            top_p=0.8,  # More diverse output\n",
        "            temperature=0.7,  # Increase randomness slightly\n",
        "            repetition_penalty=1.5,  # Stronger penalty for repeated words\n",
        "            no_repeat_ngram_size=3  # Prevent repeating 3-word sequences\n",
        "        )\n",
        "\n",
        "        summary = tokenizer.decode(summary_output[0], skip_special_tokens=True)\n",
        "        return summary.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error generating summary: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model_name = \"google/gemma-2-2b-it\"\n",
        "model, tokenizer = load_model_and_tokenizer(model_name)\n",
        "\n",
        "# ✅ Verify the casefile path exists before processing\n",
        "pdf_directory = \"/teamspace/studios/this_studio/casefile\"\n",
        "\n",
        "if not os.path.exists(pdf_directory):\n",
        "    print(f\"❌ Error: The specified directory '{pdf_directory}' does not exist.\")\n",
        "    exit(1)\n",
        "\n",
        "if model is not None and tokenizer is not None:\n",
        "    output_data = []\n",
        "\n",
        "    # Process each PDF in the directory\n",
        "    for filename in os.listdir(pdf_directory):\n",
        "        if filename.endswith(\".pdf\"):\n",
        "            pdf_path = os.path.join(pdf_directory, filename)\n",
        "            print(f\"📄 Processing: {filename}\")\n",
        "            document_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "            if document_text:\n",
        "                sanitized_text = sanitize_text(document_text)\n",
        "                summary = generate_summary(sanitized_text, model, tokenizer)\n",
        "                sanitized_summary = sanitize_text(summary)\n",
        "                output_data.append({\"Filename\": filename, \"Summary\": sanitized_summary})\n",
        "            else:\n",
        "                print(f\"⚠️ Skipping {filename} - No extractable text found.\")\n",
        "\n",
        "    # Save results to Excel and CSV\n",
        "    df = pd.DataFrame(output_data)\n",
        "    output_excel_path = \"output_summaries_2_finetuned.xlsx\"\n",
        "    output_csv_path = \"output_summaries_1.csv\"\n",
        "\n",
        "    try:\n",
        "        df.to_excel(output_excel_path, index=False)\n",
        "        print(f\"✅ Summaries saved to Excel: {output_excel_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error saving to Excel ({e}). Falling back to CSV...\")\n",
        "        df.to_csv(output_csv_path, index=False)\n",
        "        print(f\"✅ Summaries saved to CSV instead: {output_csv_path}\")\n",
        "\n",
        "    print(\"🎉 Processing complete!\")\n",
        "else:\n",
        "    print(\"❌ Failed to load model/tokenizer. Exiting.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openpyxl\n",
            "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting et-xmlfile (from openpyxl)\n",
            "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
            "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: et-xmlfile, openpyxl\n",
            "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "917f4a51cca04002a2feba32e88e26c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model loaded successfully.\n",
            "📄 Processing: converted_text.pdf\n",
            "✅ Summaries saved to Excel: output_summaries_3_finetuned.xlsx\n",
            "🎉 Processing complete!\n"
          ]
        }
      ],
      "source": [
        "#inference run 3\n",
        "import os\n",
        "import PyPDF2\n",
        "import pandas as pd\n",
        "import torch\n",
        "import re\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# ✅ Fully disable Torch Dynamo to prevent errors\n",
        "import torch._dynamo\n",
        "torch._dynamo.config.suppress_errors = True\n",
        "os.environ[\"TORCH_COMPILE\"] = \"0\"\n",
        "os.environ[\"TORCHDYNAMO_DISABLE\"] = \"1\"\n",
        "os.environ[\"TORCH_INDUCTOR_DISABLED\"] = \"1\"\n",
        "\n",
        "# Function to sanitize text by removing illegal characters\n",
        "def sanitize_text(text):\n",
        "    return re.sub(r'[\\x00-\\x1F\\x7F-\\x9F]', '', text)\n",
        "\n",
        "# Function to load the model and tokenizer and move the model to GPU\n",
        "def load_model_and_tokenizer(model_name):\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name, \n",
        "            torch_dtype=torch.float16,  # Load in fp16 for efficiency\n",
        "            device_map=\"auto\"  # Automatically use GPU if available\n",
        "        )\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            model.to(\"cuda\")\n",
        "        print(\"✅ Model loaded successfully.\")\n",
        "        return model, tokenizer\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading model/tokenizer: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Function to extract text from a PDF file\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text() or \"\"  # Ensure text is not None\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error extracting text from PDF {pdf_path}: {e}\")\n",
        "    return text.strip()\n",
        "\n",
        "# Function to generate a summary (Updated)\n",
        "def generate_summary(input_text, model, tokenizer):\n",
        "    try:\n",
        "        prompt = (\n",
        "            \"Below is a legal document. Summarize its key points concisely.\\n\\n\"\n",
        "            \"### Document:\\n{input_text}\\n\\n### Summary:\"\n",
        "        )\n",
        "\n",
        "        # Limit input text to reduce length and avoid looping\n",
        "        input_str = prompt.format(input_text=input_text[:4096])\n",
        "\n",
        "        model_inputs = tokenizer(\n",
        "            input_str,\n",
        "            return_tensors='pt',\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=4096  # Set explicit max length\n",
        "        ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        summary_output = model.generate(\n",
        "            model_inputs.input_ids,\n",
        "            max_new_tokens=256,  # Limit summary length\n",
        "            do_sample=True,      # Enable sampling\n",
        "            top_k=40,\n",
        "            top_p=0.8,\n",
        "            temperature=0.7,\n",
        "            repetition_penalty=1.5,\n",
        "            no_repeat_ngram_size=3\n",
        "        )\n",
        "\n",
        "        full_output = tokenizer.decode(summary_output[0], skip_special_tokens=True)\n",
        "        \n",
        "        # Post-process to extract only the summary\n",
        "        marker = \"### Summary:\"\n",
        "        if marker in full_output:\n",
        "            # Return text after the marker\n",
        "            summary = full_output.split(marker, 1)[1].strip()\n",
        "        else:\n",
        "            summary = full_output.strip()\n",
        "            \n",
        "        return summary\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error generating summary: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model_name = \"coderop12/Legal_Summarzation_System\"\n",
        "model, tokenizer = load_model_and_tokenizer(model_name)\n",
        "\n",
        "# ✅ Verify the casefile path exists before processing\n",
        "pdf_directory = \"/teamspace/studios/this_studio/casefile\"\n",
        "\n",
        "if not os.path.exists(pdf_directory):\n",
        "    print(f\"❌ Error: The specified directory '{pdf_directory}' does not exist.\")\n",
        "    exit(1)\n",
        "\n",
        "if model is not None and tokenizer is not None:\n",
        "    output_data = []\n",
        "\n",
        "    # Process each PDF in the directory\n",
        "    for filename in os.listdir(pdf_directory):\n",
        "        if filename.endswith(\".pdf\"):\n",
        "            pdf_path = os.path.join(pdf_directory, filename)\n",
        "            print(f\"📄 Processing: {filename}\")\n",
        "            document_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "            if document_text:\n",
        "                sanitized_text = sanitize_text(document_text)\n",
        "                summary = generate_summary(sanitized_text, model, tokenizer)\n",
        "                sanitized_summary = sanitize_text(summary)\n",
        "                output_data.append({\"Filename\": filename, \"Summary\": sanitized_summary})\n",
        "            else:\n",
        "                print(f\"⚠️ Skipping {filename} - No extractable text found.\")\n",
        "\n",
        "    # Save results to Excel and CSV\n",
        "    df = pd.DataFrame(output_data)\n",
        "    output_excel_path = \"output_summaries_3_finetuned.xlsx\"\n",
        "    output_csv_path = \"output_summaries_3_finetuned.csv\"\n",
        "\n",
        "    try:\n",
        "        df.to_excel(output_excel_path, index=False)\n",
        "        print(f\"✅ Summaries saved to Excel: {output_excel_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error saving to Excel ({e}). Falling back to CSV...\")\n",
        "        df.to_csv(output_csv_path, index=False)\n",
        "        print(f\"✅ Summaries saved to CSV instead: {output_csv_path}\")\n",
        "\n",
        "    print(\"🎉 Processing complete!\")\n",
        "else:\n",
        "    print(\"❌ Failed to load model/tokenizer. Exiting.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting sentence-transformers\n",
            "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: absl-py in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rouge-score) (2.1.0)\n",
            "Collecting nltk (from rouge-score)\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence-transformers) (4.50.0.dev0)\n",
            "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence-transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: scipy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence-transformers) (0.29.1)\n",
            "Requirement already satisfied: Pillow in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.8.61)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
            "Requirement already satisfied: click in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk->rouge-score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Downloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
            "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m153.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24986 sha256=d6718ef18288e4c6ff37f5d57f84348293a1027b95223fa5967ee9d91334c471\n",
            "  Stored in directory: /home/zeus/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: nltk, rouge-score, sentence-transformers\n",
            "Successfully installed nltk-3.9.1 rouge-score-0.1.2 sentence-transformers-3.4.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install rouge-score sentence-transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e281babb27bf4221b270da4183e91da0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc83d94470ae4ecf934062d457e25f9d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4505eae678eb4ec5aae56350198c4971",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/3.73k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c6aa1ed7201478c9708aa7ede654b14",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87c39327a4664f0291f92796094c7641",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d83f9aa5c96c4ac8a69b42a3ce7f951b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bb58ddf89974379b9468e0f3ae58ccf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5180226060fc404f89eb35f33c3f6d65",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6734a1a6f6d24313a6a36992b1f3ed4c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83ff108668504c6591de497496ecc4fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee20104c2e034a729c8782555f8a779c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "1_Pooling%2Fconfig.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'ROUGE-1': 0.13468012970513232,\n",
              " 'ROUGE-2': 0.0,\n",
              " 'ROUGE-L': 0.10101009603509871,\n",
              " 'Cosine Similarity': 0.6975638270378113}"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from rouge import Rouge\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import numpy as np\n",
        "\n",
        "# Gold standard summary (ChatGPT)\n",
        "gold_summary = \"\"\"The Court ruled that the respondents are entitled to seek a pre-deposit of only 20% of the disputed tax demand, subject to compliance with W.P. (C) 14536/2021. It highlighted that the Central Board of Direct Taxes (CBDT) has issued circulars and office memorandums, including those dated 29th February 2016 and 31st July 2017, outlining guidelines for granting a stay on tax demand recovery. These guidelines mandate that if an assessee appeals an assessment order before the first appellate authority (CIT(A)) and deposits 20% of the disputed demand, they should not be required to pay beyond this amount unless specific exceptions apply.\n",
        "\n",
        "The Court found that the petitioner was not given a pre-decisional hearing before the tax refund was adjusted, entitling them to a refund of any excess adjustments beyond 20% of the disputed demand. The Assessing Officer has the authority to grant a stay on the recovery of the remaining balance. Additionally, in cases where a stay is granted, the excess amount can be refunded manually as per ITBA Assessment Instruction No. 11. The Court concluded that the respondents violated the provisions of the Office Memorandums, which mandate granting stays based on subsequent year refund adjustments. The government must adhere to its own rules and guidelines, failing which such actions could be invalidated.\"\"\"\n",
        "\n",
        "# Model-generated summary\n",
        "model_summary = \"\"\"This judgment outlines specific guidelines related to how taxpayers facing assessments disputes should handle those situations when seeking relief against added taxes levied within pending appeals process.  \n",
        "Key takeaways include:* **Pre-deposit requirement:** Taxpayers must pay at least 2 out of every 10 taxed dollars owed if appealing income tax decisions but may request additional support based upon individual circumstances under certain conditions outlined below. This payment does not apply directly to future year's liabilities until after review proceedings have concluded.\n",
        "**Additional Details & Supporting Context**: It appears there were issues surrounding whether these payments met criteria established earlier by government regulations concerning requests for staying debt collection while challenging assessed amounts via formal avenues like Appeals Hearings. In some instances, individuals might face automatic reduction in available funds even though ongoing litigation continues; however, it seems clear now that courts will ensure fairness across all parties involved throughout each stage - ensuring both taxpayer rights AND proper administration of revenue collections.**\"\"\"\n",
        "\n",
        "# Compute ROUGE scores\n",
        "rouge = Rouge()\n",
        "rouge_scores = rouge.get_scores(model_summary, gold_summary, avg=True)\n",
        "\n",
        "# Load SentenceTransformer for semantic similarity\n",
        "model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
        "gold_embedding = model.encode(gold_summary, convert_to_tensor=True)\n",
        "model_embedding = model.encode(model_summary, convert_to_tensor=True)\n",
        "\n",
        "# Compute cosine similarity\n",
        "cosine_sim = util.pytorch_cos_sim(gold_embedding, model_embedding).item()\n",
        "\n",
        "# Display results\n",
        "{\n",
        "    \"ROUGE-1\": rouge_scores[\"rouge-1\"][\"f\"],\n",
        "    \"ROUGE-2\": rouge_scores[\"rouge-2\"][\"f\"],\n",
        "    \"ROUGE-L\": rouge_scores[\"rouge-l\"][\"f\"],\n",
        "    \"Cosine Similarity\": cosine_sim\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ROUGE-1': 0.26548672083640074,\n",
              " 'ROUGE-2': 0.08252426685891726,\n",
              " 'ROUGE-L': 0.2182890807184067,\n",
              " 'Cosine Similarity': 0.6975638270378113}"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from rouge import Rouge\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Updated system summary with fine-tuned and ChatGPT summaries\n",
        "model_summary = \"\"\"This judgment outlines specific guidelines related to how taxpayers facing assessments disputes should handle those situations when seeking relief against added taxes levied within pending appeals process.  \n",
        "Key takeaways include:  \n",
        "* **Pre-deposit requirement:** Taxpayers must pay at least 2 out of every 10 taxed dollars owed if appealing income tax decisions but may request additional support based upon individual circumstances under certain conditions outlined below. This payment does not apply directly to future year's liabilities until after review proceedings have concluded.  \n",
        "\n",
        "**Additional Details & Supporting Context**:  \n",
        "It appears there were issues surrounding whether these payments met criteria established earlier by government regulations concerning requests for staying debt collection while challenging assessed amounts via formal avenues like Appeals Hearings. In some instances, individuals might face automatic reduction in available funds even though ongoing litigation continues; however, it seems clear now that courts will ensure fairness across all parties involved throughout each stage - ensuring both taxpayer rights AND proper administration of revenue collections.  \n",
        "\n",
        "**ChatGPT Summary (Court Ruling Summary):**  \n",
        "The court ruled that tax authorities can seek only **20% of the disputed demand** as a pre-deposit during appeals, and any excess adjustments must be refunded. **Assessing Officers have the authority to grant a stay** on recovery. The government must adhere to **CBDT guidelines**, failing which actions may be invalidated.\n",
        "\"\"\"\n",
        "\n",
        "# Compute ROUGE scores\n",
        "rouge = Rouge()\n",
        "rouge_scores = rouge.get_scores(model_summary, gold_summary, avg=True)\n",
        "\n",
        "# Load SentenceTransformer for semantic similarity\n",
        "model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
        "gold_embedding = model.encode(gold_summary, convert_to_tensor=True)\n",
        "model_embedding = model.encode(model_summary, convert_to_tensor=True)\n",
        "\n",
        "# Compute cosine similarity\n",
        "cosine_sim = util.pytorch_cos_sim(gold_embedding, model_embedding).item()\n",
        "\n",
        "# Display results\n",
        "{\n",
        "    \"ROUGE-1\": rouge_scores[\"rouge-1\"][\"f\"],\n",
        "    \"ROUGE-2\": rouge_scores[\"rouge-2\"][\"f\"],\n",
        "    \"ROUGE-L\": rouge_scores[\"rouge-l\"][\"f\"],\n",
        "    \"Cosine Similarity\": cosine_sim\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: six in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rouge) (1.17.0)\n",
            "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openpyxl in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from openpyxl) (2.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repo 'coderop12/Legal_Summarzation_System' has been deleted.\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import delete_repo, login\n",
        "\n",
        "# 1. Log in with your Hugging Face token\n",
        "\n",
        "# 2. Delete the repository\n",
        "repo_id = \"coderop12/Legal_Summarzation_System\"  # \"username/repo_name\"\n",
        "delete_repo(repo_id=repo_id, repo_type=\"model\")\n",
        "\n",
        "print(f\"Repo '{repo_id}' has been deleted.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from optuna) (24.2)\n",
            "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
            "  Downloading SQLAlchemy-2.0.38-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.4.2->optuna)\n",
            "  Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "Downloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
            "Downloading SQLAlchemy-2.0.38-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m180.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (599 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.5/599.5 kB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: Mako, greenlet, colorlog, sqlalchemy, alembic, optuna\n",
            "Successfully installed Mako-1.3.9 alembic-1.14.1 colorlog-6.9.0 greenlet-3.1.1 optuna-4.2.1 sqlalchemy-2.0.38\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82f58f9e876a4be0a2acae8d98f2057e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 06:26:54,475] A new study created in memory with name: no-name-b8f6e9f7-6c3c-4c3e-999c-583bed827d41\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model loaded successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_3134/1898181306.py:127: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  top_p = trial.suggest_uniform(\"top_p\", 0.6, 0.95)\n",
            "/tmp/ipykernel_3134/1898181306.py:128: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  temperature = trial.suggest_loguniform(\"temperature\", 0.5, 1.5)\n",
            "/tmp/ipykernel_3134/1898181306.py:129: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  repetition_penalty = trial.suggest_uniform(\"repetition_penalty\", 1.0, 2.0)\n",
            "[I 2025-02-28 06:27:04,289] Trial 0 finished with value: 0.026871401151631478 and parameters: {'top_k': 46, 'top_p': 0.8520246039900785, 'temperature': 1.350824527826988, 'repetition_penalty': 1.3364138564986499, 'no_repeat_ngram_size': 5}. Best is trial 0 with value: 0.026871401151631478.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 0: score=0.0269 with params: top_k=46, top_p=0.85, temperature=1.35, repetition_penalty=1.34, no_repeat_ngram_size=5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 06:27:11,817] Trial 1 finished with value: 0.054673721340388004 and parameters: {'top_k': 59, 'top_p': 0.8161857308415474, 'temperature': 0.9042019985067397, 'repetition_penalty': 1.6515748797760212, 'no_repeat_ngram_size': 5}. Best is trial 1 with value: 0.054673721340388004.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 1: score=0.0547 with params: top_k=59, top_p=0.82, temperature=0.90, repetition_penalty=1.65, no_repeat_ngram_size=5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 06:27:20,815] Trial 2 finished with value: 0.05259515570934256 and parameters: {'top_k': 52, 'top_p': 0.6724843763401622, 'temperature': 1.4407423713154277, 'repetition_penalty': 1.4313346041230484, 'no_repeat_ngram_size': 5}. Best is trial 1 with value: 0.054673721340388004.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 2: score=0.0526 with params: top_k=52, top_p=0.67, temperature=1.44, repetition_penalty=1.43, no_repeat_ngram_size=5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 06:27:24,685] Trial 3 finished with value: 0.10950080515297907 and parameters: {'top_k': 54, 'top_p': 0.9304373287991912, 'temperature': 1.119390927509042, 'repetition_penalty': 1.4365684393978444, 'no_repeat_ngram_size': 2}. Best is trial 3 with value: 0.10950080515297907.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 3: score=0.1095 with params: top_k=54, top_p=0.93, temperature=1.12, repetition_penalty=1.44, no_repeat_ngram_size=2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 06:27:33,657] Trial 4 finished with value: 0.05166051660516605 and parameters: {'top_k': 33, 'top_p': 0.8925898504371182, 'temperature': 0.6944585918616094, 'repetition_penalty': 1.7380656624655435, 'no_repeat_ngram_size': 4}. Best is trial 3 with value: 0.10950080515297907.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 4: score=0.0517 with params: top_k=33, top_p=0.89, temperature=0.69, repetition_penalty=1.74, no_repeat_ngram_size=4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 06:27:34,877] Trial 5 finished with value: 0.18840579710144928 and parameters: {'top_k': 43, 'top_p': 0.7673380052064728, 'temperature': 0.6111679958539, 'repetition_penalty': 1.5219379518127714, 'no_repeat_ngram_size': 5}. Best is trial 5 with value: 0.18840579710144928.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 5: score=0.1884 with params: top_k=43, top_p=0.77, temperature=0.61, repetition_penalty=1.52, no_repeat_ngram_size=5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 06:27:43,925] Trial 6 finished with value: 0.06438068579426172 and parameters: {'top_k': 47, 'top_p': 0.9094564846480873, 'temperature': 0.9857312638025773, 'repetition_penalty': 1.9997304652653645, 'no_repeat_ngram_size': 3}. Best is trial 5 with value: 0.18840579710144928.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 6: score=0.0644 with params: top_k=47, top_p=0.91, temperature=0.99, repetition_penalty=2.00, no_repeat_ngram_size=3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 06:27:44,664] Trial 7 finished with value: 0.15757575757575756 and parameters: {'top_k': 44, 'top_p': 0.6629415771431802, 'temperature': 0.6162886842856679, 'repetition_penalty': 1.945508888631821, 'no_repeat_ngram_size': 2}. Best is trial 5 with value: 0.18840579710144928.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 7: score=0.1576 with params: top_k=44, top_p=0.66, temperature=0.62, repetition_penalty=1.95, no_repeat_ngram_size=2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 06:27:53,699] Trial 8 finished with value: 0.026817219477769938 and parameters: {'top_k': 95, 'top_p': 0.9092888192864168, 'temperature': 0.8070390291298929, 'repetition_penalty': 1.6664228113166155, 'no_repeat_ngram_size': 5}. Best is trial 5 with value: 0.18840579710144928.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 8: score=0.0268 with params: top_k=95, top_p=0.91, temperature=0.81, repetition_penalty=1.67, no_repeat_ngram_size=5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 06:27:55,491] Trial 9 finished with value: 0.2059800664451827 and parameters: {'top_k': 97, 'top_p': 0.627233300728278, 'temperature': 0.722404570283385, 'repetition_penalty': 1.2254330744835047, 'no_repeat_ngram_size': 4}. Best is trial 9 with value: 0.2059800664451827.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 9: score=0.2060 with params: top_k=97, top_p=0.63, temperature=0.72, repetition_penalty=1.23, no_repeat_ngram_size=4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 06:27:57,577] Trial 10 finished with value: 0.23100303951367782 and parameters: {'top_k': 99, 'top_p': 0.6193927634347278, 'temperature': 0.5279946270879468, 'repetition_penalty': 1.0449715770159638, 'no_repeat_ngram_size': 3}. Best is trial 10 with value: 0.23100303951367782.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 10: score=0.2310 with params: top_k=99, top_p=0.62, temperature=0.53, repetition_penalty=1.04, no_repeat_ngram_size=3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 06:27:58,982] Trial 11 finished with value: 0.2938775510204082 and parameters: {'top_k': 99, 'top_p': 0.6051211262385418, 'temperature': 0.5171226845603978, 'repetition_penalty': 1.1163889069525519, 'no_repeat_ngram_size': 3}. Best is trial 11 with value: 0.2938775510204082.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 11: score=0.2939 with params: top_k=99, top_p=0.61, temperature=0.52, repetition_penalty=1.12, no_repeat_ngram_size=3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 06:28:04,110] Trial 12 finished with value: 0.03337969401947149 and parameters: {'top_k': 79, 'top_p': 0.6021791361437088, 'temperature': 0.5256420204394749, 'repetition_penalty': 1.0399139991749244, 'no_repeat_ngram_size': 3}. Best is trial 11 with value: 0.2938775510204082.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 12: score=0.0334 with params: top_k=79, top_p=0.60, temperature=0.53, repetition_penalty=1.04, no_repeat_ngram_size=3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 06:28:13,279] Trial 13 finished with value: 0.0610079575596817 and parameters: {'top_k': 79, 'top_p': 0.6998162176886097, 'temperature': 0.5034830038538135, 'repetition_penalty': 1.068273470658218, 'no_repeat_ngram_size': 3}. Best is trial 11 with value: 0.2938775510204082.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 13: score=0.0610 with params: top_k=79, top_p=0.70, temperature=0.50, repetition_penalty=1.07, no_repeat_ngram_size=3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 06:28:22,594] Trial 14 finished with value: 0.03838517538054269 and parameters: {'top_k': 82, 'top_p': 0.7438720330425465, 'temperature': 0.6030557222751808, 'repetition_penalty': 1.1986732273287557, 'no_repeat_ngram_size': 3}. Best is trial 11 with value: 0.2938775510204082.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 14: score=0.0384 with params: top_k=82, top_p=0.74, temperature=0.60, repetition_penalty=1.20, no_repeat_ngram_size=3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 06:28:24,048] Trial 15 finished with value: 0.2302158273381295 and parameters: {'top_k': 70, 'top_p': 0.7264428361229209, 'temperature': 0.5544254152435644, 'repetition_penalty': 1.1781399602991156, 'no_repeat_ngram_size': 2}. Best is trial 11 with value: 0.2938775510204082.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 15: score=0.2302 with params: top_k=70, top_p=0.73, temperature=0.55, repetition_penalty=1.18, no_repeat_ngram_size=2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 06:28:33,049] Trial 16 finished with value: 0.05714285714285714 and parameters: {'top_k': 89, 'top_p': 0.6387680280125874, 'temperature': 0.7107545920284921, 'repetition_penalty': 1.007995645379109, 'no_repeat_ngram_size': 4}. Best is trial 11 with value: 0.2938775510204082.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 16: score=0.0571 with params: top_k=89, top_p=0.64, temperature=0.71, repetition_penalty=1.01, no_repeat_ngram_size=4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 06:28:34,778] Trial 17 finished with value: 0.24918032786885247 and parameters: {'top_k': 100, 'top_p': 0.6057870800150593, 'temperature': 0.5703089036934398, 'repetition_penalty': 1.3048363195513406, 'no_repeat_ngram_size': 3}. Best is trial 11 with value: 0.2938775510204082.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 17: score=0.2492 with params: top_k=100, top_p=0.61, temperature=0.57, repetition_penalty=1.30, no_repeat_ngram_size=3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 06:28:36,940] Trial 18 finished with value: 0.18848167539267016 and parameters: {'top_k': 21, 'top_p': 0.686913519884336, 'temperature': 0.78869188121657, 'repetition_penalty': 1.3342435921771238, 'no_repeat_ngram_size': 4}. Best is trial 11 with value: 0.2938775510204082.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 18: score=0.1885 with params: top_k=21, top_p=0.69, temperature=0.79, repetition_penalty=1.33, no_repeat_ngram_size=4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 06:28:45,933] Trial 19 finished with value: 0.06597222222222222 and parameters: {'top_k': 69, 'top_p': 0.8032778940009122, 'temperature': 0.6611777023405808, 'repetition_penalty': 1.2966563033930394, 'no_repeat_ngram_size': 2}. Best is trial 11 with value: 0.2938775510204082.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 19: score=0.0660 with params: top_k=69, top_p=0.80, temperature=0.66, repetition_penalty=1.30, no_repeat_ngram_size=2\n",
            "Best hyperparameters found: {'top_k': 99, 'top_p': 0.6051211262385418, 'temperature': 0.5171226845603978, 'repetition_penalty': 1.1163889069525519, 'no_repeat_ngram_size': 3}\n",
            "📄 Processing: converted_text.pdf\n",
            "✅ Summaries saved to Excel: output_summaries_3_finetuned.xlsx\n",
            "🎉 Processing complete!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import PyPDF2\n",
        "import pandas as pd\n",
        "import torch\n",
        "import re\n",
        "import difflib\n",
        "import optuna\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# ✅ Fully disable Torch Dynamo to prevent errors\n",
        "import torch._dynamo\n",
        "torch._dynamo.config.suppress_errors = True\n",
        "os.environ[\"TORCH_COMPILE\"] = \"0\"\n",
        "os.environ[\"TORCHDYNAMO_DISABLE\"] = \"1\"\n",
        "os.environ[\"TORCH_INDUCTOR_DISABLED\"] = \"1\"\n",
        "\n",
        "# Function to sanitize text by removing illegal characters\n",
        "def sanitize_text(text):\n",
        "    return re.sub(r'[\\x00-\\x1F\\x7F-\\x9F]', '', text)\n",
        "\n",
        "# Function to load the model and tokenizer and move the model to GPU\n",
        "def load_model_and_tokenizer(model_name):\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name, \n",
        "            torch_dtype=torch.float16,  # Load in fp16 for efficiency\n",
        "            device_map=\"auto\"  # Automatically use GPU if available\n",
        "        )\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            model.to(\"cuda\")\n",
        "        print(\"✅ Model loaded successfully.\")\n",
        "        return model, tokenizer\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading model/tokenizer: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Function to extract text from a PDF file\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text() or \"\"  # Ensure text is not None\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error extracting text from PDF {pdf_path}: {e}\")\n",
        "    return text.strip()\n",
        "\n",
        "# Function to generate summary with tunable parameters\n",
        "def generate_summary_custom(input_text, model, tokenizer,\n",
        "                            top_k, top_p, temperature, repetition_penalty, no_repeat_ngram_size):\n",
        "    try:\n",
        "        prompt = (\n",
        "            \"Below is a legal document. Summarize its key points concisely.\\n\\n\"\n",
        "            \"### Document:\\n{input_text}\\n\\n### Summary:\"\n",
        "        )\n",
        "        # Limit input text to reduce length and avoid looping\n",
        "        input_str = prompt.format(input_text=input_text[:4096])\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        model_inputs = tokenizer(\n",
        "            input_str,\n",
        "            return_tensors='pt',\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=4096\n",
        "        ).to(device)\n",
        "\n",
        "        summary_output = model.generate(\n",
        "            model_inputs.input_ids,\n",
        "            max_new_tokens=256,  # Limit summary length\n",
        "            do_sample=True,      # Enable sampling\n",
        "            top_k=top_k,\n",
        "            top_p=top_p,\n",
        "            temperature=temperature,\n",
        "            repetition_penalty=repetition_penalty,\n",
        "            no_repeat_ngram_size=no_repeat_ngram_size\n",
        "        )\n",
        "\n",
        "        full_output = tokenizer.decode(summary_output[0], skip_special_tokens=True)\n",
        "        # Post-process to extract only the summary\n",
        "        marker = \"### Summary:\"\n",
        "        if marker in full_output:\n",
        "            summary = full_output.split(marker, 1)[1].strip()\n",
        "        else:\n",
        "            summary = full_output.strip()\n",
        "        return summary\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error generating summary: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# For production, use default generation parameters\n",
        "def generate_summary(input_text, model, tokenizer):\n",
        "    return generate_summary_custom(\n",
        "        input_text, model, tokenizer,\n",
        "        top_k=40,\n",
        "        top_p=0.8,\n",
        "        temperature=0.7,\n",
        "        repetition_penalty=1.5,\n",
        "        no_repeat_ngram_size=3\n",
        "    )\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model_name = \"coderop12/Legal_Summarzation_System\"\n",
        "model, tokenizer = load_model_and_tokenizer(model_name)\n",
        "\n",
        "# ✅ Verify the casefile path exists before processing\n",
        "pdf_directory = \"/teamspace/studios/this_studio/casefile\"\n",
        "\n",
        "if not os.path.exists(pdf_directory):\n",
        "    print(f\"❌ Error: The specified directory '{pdf_directory}' does not exist.\")\n",
        "    exit(1)\n",
        "\n",
        "# =======================\n",
        "# Hyperparameter Tuning\n",
        "# =======================\n",
        "\n",
        "# For hyperparameter tuning, we assume you have at least one sample document and a reference summary.\n",
        "# Replace these with your actual validation examples.\n",
        "sample_document = \"Your sample legal document text goes here. This should be representative of your documents.\"\n",
        "reference_summary = \"Your expected concise summary for the sample document.\"\n",
        "\n",
        "def objective(trial):\n",
        "    # Define the hyperparameter search space\n",
        "    top_k = trial.suggest_int(\"top_k\", 20, 100)\n",
        "    top_p = trial.suggest_uniform(\"top_p\", 0.6, 0.95)\n",
        "    temperature = trial.suggest_loguniform(\"temperature\", 0.5, 1.5)\n",
        "    repetition_penalty = trial.suggest_uniform(\"repetition_penalty\", 1.0, 2.0)\n",
        "    no_repeat_ngram_size = trial.suggest_int(\"no_repeat_ngram_size\", 2, 5)\n",
        "\n",
        "    # Generate summary using the custom function\n",
        "    summary = generate_summary_custom(\n",
        "        sample_document, model, tokenizer,\n",
        "        top_k=top_k,\n",
        "        top_p=top_p,\n",
        "        temperature=temperature,\n",
        "        repetition_penalty=repetition_penalty,\n",
        "        no_repeat_ngram_size=no_repeat_ngram_size\n",
        "    )\n",
        "    \n",
        "    # Calculate a simple similarity score using difflib\n",
        "    # (Replace with a more robust metric for real evaluation, e.g., ROUGE)\n",
        "    score = difflib.SequenceMatcher(None, summary, reference_summary).ratio()\n",
        "    print(f\"Trial {trial.number}: score={score:.4f} with params: top_k={top_k}, top_p={top_p:.2f}, temperature={temperature:.2f}, repetition_penalty={repetition_penalty:.2f}, no_repeat_ngram_size={no_repeat_ngram_size}\")\n",
        "    return score\n",
        "\n",
        "# Run hyperparameter tuning\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=20)\n",
        "print(\"Best hyperparameters found:\", study.best_trial.params)\n",
        "\n",
        "# Optionally, you can update your production generation parameters based on the best trial.\n",
        "best_params = study.best_trial.params\n",
        "\n",
        "# =======================\n",
        "# Inference / Processing PDFs\n",
        "# =======================\n",
        "\n",
        "if model is not None and tokenizer is not None:\n",
        "    output_data = []\n",
        "\n",
        "    # Process each PDF in the directory\n",
        "    for filename in os.listdir(pdf_directory):\n",
        "        if filename.endswith(\".pdf\"):\n",
        "            pdf_path = os.path.join(pdf_directory, filename)\n",
        "            print(f\"📄 Processing: {filename}\")\n",
        "            document_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "            if document_text:\n",
        "                sanitized_text = sanitize_text(document_text)\n",
        "                # Use best parameters found from tuning\n",
        "                summary = generate_summary_custom(\n",
        "                    sanitized_text, model, tokenizer,\n",
        "                    top_k=best_params.get(\"top_k\", 40),\n",
        "                    top_p=best_params.get(\"top_p\", 0.8),\n",
        "                    temperature=best_params.get(\"temperature\", 0.7),\n",
        "                    repetition_penalty=best_params.get(\"repetition_penalty\", 1.5),\n",
        "                    no_repeat_ngram_size=best_params.get(\"no_repeat_ngram_size\", 3)\n",
        "                )\n",
        "                sanitized_summary = sanitize_text(summary)\n",
        "                output_data.append({\"Filename\": filename, \"Summary\": sanitized_summary})\n",
        "            else:\n",
        "                print(f\"⚠️ Skipping {filename} - No extractable text found.\")\n",
        "\n",
        "    # Save results to Excel and CSV\n",
        "    df = pd.DataFrame(output_data)\n",
        "    output_excel_path = \"output_summaries_3_finetuned.xlsx\"\n",
        "    output_csv_path = \"output_summaries_3_finetuned.csv\"\n",
        "\n",
        "    try:\n",
        "        df.to_excel(output_excel_path, index=False)\n",
        "        print(f\"✅ Summaries saved to Excel: {output_excel_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error saving to Excel ({e}). Falling back to CSV...\")\n",
        "        df.to_csv(output_csv_path, index=False)\n",
        "        print(f\"✅ Summaries saved to CSV instead: {output_csv_path}\")\n",
        "\n",
        "    print(\"🎉 Processing complete!\")\n",
        "else:\n",
        "    print(\"❌ Failed to load model/tokenizer. Exiting.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c65866cc5fe4471491003ed0b52db2bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6a5bb3d45b14dd1b75b6da35161ac8e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4241f4de1f6a4a66a5b0b052d817d166",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c58f96deb0ff4d359df446a5125482a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16bc5682f8104774bdeb7b102ea6bc10",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a310159f48e940eb9333bc268f45dce0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42f3901021564d23ad220c260d361c3c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba474efd907543518f0c228d43eab935",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1daef2d6210e4fd9989b23cff702dff1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0561e0cc501f43538ca81655de94fc7b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7944870dbaab42a18683afa029651629",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "1_Pooling%2Fconfig.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROUGE Scores:\n",
            "  rouge1: F1 = 0.9086, Precision = 0.8865, Recall = 0.9318\n",
            "  rouge2: F1 = 0.8802, Precision = 0.8587, Recall = 0.9029\n",
            "  rougeL: F1 = 0.9086, Precision = 0.8865, Recall = 0.9318\n",
            "\n",
            "Cosine Similarity: 0.9847\n"
          ]
        }
      ],
      "source": [
        "from rouge_score import rouge_scorer\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Replace these with your actual summaries.\n",
        "generated_summary = (\n",
        "    \"This judgment deals with the issue of whether the Assessing Officers have the power under section 263 of the \"\n",
        "    \"Income Tax Act, 1961 to adjust the refund of the previous year against the current year’s liability. The High Court \"\n",
        "    \"of Delhi observed that it is not permissible to make any adjustment of the refund without giving any opportunity of \"\n",
        "    \"hearing to the taxpayer. It also observed that if the taxpayer makes a payment towards the disputed amount, then he \"\n",
        "    \"will be entitled to get his refund adjusted accordingly. The Tribunal relied upon the judgments of the Supreme Court \"\n",
        "    \"in the matter of M/S. Reliance Industries Ltd. v. Union of India & Ors. [W.P.(C) No. 10719 of 18] and others wherein \"\n",
        "    \"the Hon’ble Supreme Court held, “It is imperative that the Department should not proceed with the recovery proceedings \"\n",
        "    \"without affording an opportunity of being heard to the assesse.” The Hon’able High Court observed: “The facts of the \"\n",
        "    \"present case show that the Assessing officer did not give any opportunity to the Petitioner to explain his position and \"\n",
        "    \"therefore, the impug\"  # Note: Generated summary appears truncated.\n",
        ")\n",
        "\n",
        "# Provide your complete reference summary here.\n",
        "reference_summary = (\n",
        "    \"This judgment deals with the issue of whether the Assessing Officers have the power under section 263 of the Income Tax \"\n",
        "    \"Act, 1961 to adjust the refund of the previous year against the current year’s liability. The High Court of Delhi observed \"\n",
        "    \"that it is not permissible to make any adjustment of the refund without giving any opportunity of hearing to the taxpayer. \"\n",
        "    \"It also observed that if the taxpayer makes a payment towards the disputed amount, then he will be entitled to get his refund \"\n",
        "    \"adjusted accordingly. The Tribunal relied upon the judgments of the Supreme Court in the matter of M/S. Reliance Industries Ltd. \"\n",
        "    \"v. Union of India & Ors. [W.P.(C) No. 10719 of 18] and others, wherein the Hon’ble Supreme Court held, “It is imperative that the \"\n",
        "    \"Department should not proceed with the recovery proceedings without affording an opportunity of being heard to the assesse.” \"\n",
        "    \"The Hon’able High Court further observed that the petitioner's right to a hearing was violated, and accordingly, the orders \"\n",
        "    \"passed were invalid.\"\n",
        ")\n",
        "\n",
        "def compare_summaries(generated, reference):\n",
        "    # Compute ROUGE scores\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    rouge_scores = scorer.score(reference, generated)\n",
        "    \n",
        "    # Compute cosine similarity between summaries using SentenceTransformer\n",
        "    embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    embeddings = embedder.encode([generated, reference])\n",
        "    cosine_similarity = util.cos_sim(embeddings[0], embeddings[1]).item()\n",
        "    \n",
        "    return rouge_scores, cosine_similarity\n",
        "\n",
        "# Evaluate the summaries.\n",
        "scores, cosine_sim = compare_summaries(generated_summary, reference_summary)\n",
        "\n",
        "print(\"ROUGE Scores:\")\n",
        "for metric, score in scores.items():\n",
        "    print(f\"  {metric}: F1 = {score.fmeasure:.4f}, Precision = {score.precision:.4f}, Recall = {score.recall:.4f}\")\n",
        "\n",
        "print(f\"\\nCosine Similarity: {cosine_sim:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROUGE Scores:\n",
            "  rouge1: F1 = 0.3553, Precision = 0.2919, Recall = 0.4538\n",
            "  rouge2: F1 = 0.0861, Precision = 0.0707, Recall = 0.1102\n",
            "  rougeL: F1 = 0.1842, Precision = 0.1514, Recall = 0.2353\n",
            "\n",
            "Cosine Similarity: 0.6897\n"
          ]
        }
      ],
      "source": [
        "from rouge_score import rouge_scorer\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Base summary (as provided)\n",
        "base_summary = (\n",
        "    \"The court held that respondents are entitled only to a pre-deposit of 20% of the disputed tax demand, \"\n",
        "    \"provided that the petitioner receives an opportunity for a pre-decisional hearing. Citing various circulars \"\n",
        "    \"and office memorandums issued between February 2016 and July 2017, the court emphasized that in cases where \"\n",
        "    \"an assessee challenges disallowances without a proper hearing, any refund adjustments beyond 20% must be returned \"\n",
        "    \"until the first appeal is resolved. Additionally, assessing officers have the authority to grant a stay on the recovery \"\n",
        "    \"of the remaining demand and process manual refunds in line with ITBA assessment instructions. The court concluded \"\n",
        "    \"that failure to adhere to these established procedures would render the actions of the respondents invalid.\"\n",
        ")\n",
        "\n",
        "# \"My summary\" provided (note: it is truncated)\n",
        "my_summary = (\n",
        "    \"This judgment deals with the issue of whether the Assessing Officers have the power under section 263 of the Income Tax Act, \"\n",
        "    \"1961 to adjust the refund of the previous year against the current year’s liability. The High Court of Delhi observed that it \"\n",
        "    \"is not permissible to make any adjustment of the refund without giving any opportunity of hearing to the taxpayer. It also observed \"\n",
        "    \"that if the taxpayer makes a payment towards the disputed amount, then he will be entitled to get his refund adjusted accordingly. \"\n",
        "    \"The Tribunal relied upon the judgments of the Supreme Court in the matter of M/S. Reliance Industries Ltd. v. Union of India & Ors. \"\n",
        "    \"[W.P.(C) No. 10719 of 18] and others wherein the Hon’ble Supreme Court held, “It is imperative that the Department should not proceed \"\n",
        "    \"with the recovery proceedings without affording an opportunity of being heard to the assesse.” The Hon’able High Court observed: “The \"\n",
        "    \"facts of the present case show that the Assessing officer did not give any opportunity to the Petitioner to explain his position and therefore, \"\n",
        "    \"the impug\"\n",
        ")\n",
        "\n",
        "def compare_summaries(summary1, summary2):\n",
        "    # Calculate ROUGE scores (using ROUGE-1, ROUGE-2, and ROUGE-L)\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    rouge_scores = scorer.score(summary1, summary2)\n",
        "    \n",
        "    # Calculate cosine similarity using a pre-trained SentenceTransformer model\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    embeddings = model.encode([summary1, summary2])\n",
        "    cosine_similarity = util.cos_sim(embeddings[0], embeddings[1]).item()\n",
        "    \n",
        "    return rouge_scores, cosine_similarity\n",
        "\n",
        "# Compare the base summary with \"my summary\"\n",
        "scores, cosine_sim = compare_summaries(base_summary, my_summary)\n",
        "\n",
        "# Print the evaluation results\n",
        "print(\"ROUGE Scores:\")\n",
        "for metric, score in scores.items():\n",
        "    print(f\"  {metric}: F1 = {score.fmeasure:.4f}, Precision = {score.precision:.4f}, Recall = {score.recall:.4f}\")\n",
        "\n",
        "print(f\"\\nCosine Similarity: {cosine_sim:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence_transformers) (4.50.0.dev0)\n",
            "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence_transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence_transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: scipy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence_transformers) (0.29.1)\n",
            "Requirement already satisfied: Pillow in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence_transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.12.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.8.61)\n",
            "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Downloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
            "Installing collected packages: sentence_transformers\n",
            "Successfully installed sentence_transformers-3.4.1\n",
            "Requirement already satisfied: rouge_score in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rouge_score) (2.1.0)\n",
            "Requirement already satisfied: nltk in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk->rouge_score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk->rouge_score) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence_transformers\n",
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a57a6d14de154d3c8a792b5de1316bc7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 07:12:04,221] A new study created in memory with name: no-name-acfff696-d057-421d-a832-cb750e94fe31\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model and tokenizer loaded successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 07:12:13,379] Trial 0 finished with value: -0.7236059479553902 and parameters: {'top_k': 74, 'top_p': 0.8224207787265655, 'temperature': 0.6904628500724943, 'repetition_penalty': 1.7702606234337228, 'no_repeat_ngram_size': 3, 'max_new_tokens': 248}. Best is trial 0 with value: -0.7236059479553902.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 0: score=-0.7236, length=183, params: top_k=74, top_p=0.82, temp=0.69, rep_pen=1.77, no_rep_ngram=3, max_tokens=248\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 07:12:19,264] Trial 1 finished with value: 0.008118811881188126 and parameters: {'top_k': 43, 'top_p': 0.8961012983024321, 'temperature': 0.561663586916444, 'repetition_penalty': 1.804872599464883, 'no_repeat_ngram_size': 2, 'max_new_tokens': 168}. Best is trial 1 with value: 0.008118811881188126.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 1: score=0.0081, length=105, params: top_k=43, top_p=0.90, temp=0.56, rep_pen=1.80, no_rep_ngram=2, max_tokens=168\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 07:12:26,373] Trial 2 finished with value: -0.11834123222748819 and parameters: {'top_k': 36, 'top_p': 0.7284952385214016, 'temperature': 0.821537937879596, 'repetition_penalty': 1.9767877548698336, 'no_repeat_ngram_size': 2, 'max_new_tokens': 198}. Best is trial 1 with value: 0.008118811881188126.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 2: score=-0.1183, length=124, params: top_k=36, top_p=0.73, temp=0.82, rep_pen=1.98, no_rep_ngram=2, max_tokens=198\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 07:12:32,039] Trial 3 finished with value: -0.3033333333333334 and parameters: {'top_k': 67, 'top_p': 0.6203791803811505, 'temperature': 0.5983036352833041, 'repetition_penalty': 1.9147372282093063, 'no_repeat_ngram_size': 3, 'max_new_tokens': 161}. Best is trial 1 with value: 0.008118811881188126.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 3: score=-0.3033, length=137, params: top_k=67, top_p=0.62, temp=0.60, rep_pen=1.91, no_rep_ngram=3, max_tokens=161\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 07:12:37,223] Trial 4 finished with value: -0.032364532019704434 and parameters: {'top_k': 26, 'top_p': 0.7670057081857935, 'temperature': 0.9037083247385638, 'repetition_penalty': 1.9427089014327055, 'no_repeat_ngram_size': 5, 'max_new_tokens': 145}. Best is trial 1 with value: 0.008118811881188126.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 4: score=-0.0324, length=112, params: top_k=26, top_p=0.77, temp=0.90, rep_pen=1.94, no_rep_ngram=5, max_tokens=145\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 07:12:43,786] Trial 5 finished with value: -0.24821428571428575 and parameters: {'top_k': 41, 'top_p': 0.8336285864446431, 'temperature': 0.6794788985132385, 'repetition_penalty': 1.6720131401087253, 'no_repeat_ngram_size': 4, 'max_new_tokens': 184}. Best is trial 1 with value: 0.008118811881188126.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 5: score=-0.2482, length=140, params: top_k=41, top_p=0.83, temp=0.68, rep_pen=1.67, no_rep_ngram=4, max_tokens=184\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 07:12:52,346] Trial 6 finished with value: -0.5927131782945736 and parameters: {'top_k': 68, 'top_p': 0.9251203638692991, 'temperature': 1.449199550026813, 'repetition_penalty': 1.3585231524984138, 'no_repeat_ngram_size': 3, 'max_new_tokens': 241}. Best is trial 1 with value: 0.008118811881188126.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 6: score=-0.5927, length=170, params: top_k=68, top_p=0.93, temp=1.45, rep_pen=1.36, no_rep_ngram=3, max_tokens=241\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 07:13:00,783] Trial 7 finished with value: -0.7108823529411765 and parameters: {'top_k': 73, 'top_p': 0.7931652334514427, 'temperature': 0.9764662956751525, 'repetition_penalty': 1.8275762863954075, 'no_repeat_ngram_size': 4, 'max_new_tokens': 235}. Best is trial 1 with value: 0.008118811881188126.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 7: score=-0.7109, length=181, params: top_k=73, top_p=0.79, temp=0.98, rep_pen=1.83, no_rep_ngram=4, max_tokens=235\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 07:13:07,512] Trial 8 finished with value: -0.34434599156118145 and parameters: {'top_k': 47, 'top_p': 0.7128919522462567, 'temperature': 1.1646722717799765, 'repetition_penalty': 1.706737014090148, 'no_repeat_ngram_size': 4, 'max_new_tokens': 191}. Best is trial 1 with value: 0.008118811881188126.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 8: score=-0.3443, length=151, params: top_k=47, top_p=0.71, temp=1.16, rep_pen=1.71, no_rep_ngram=4, max_tokens=191\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 07:13:14,903] Trial 9 finished with value: -0.4787096774193549 and parameters: {'top_k': 46, 'top_p': 0.6152062245287181, 'temperature': 0.6396051647990693, 'repetition_penalty': 1.6333604522847631, 'no_repeat_ngram_size': 2, 'max_new_tokens': 202}. Best is trial 1 with value: 0.008118811881188126.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 9: score=-0.4787, length=156, params: top_k=46, top_p=0.62, temp=0.64, rep_pen=1.63, no_rep_ngram=2, max_tokens=202\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 07:13:19,785] Trial 10 finished with value: 0.27932960893854747 and parameters: {'top_k': 96, 'top_p': 0.9491087361216234, 'temperature': 0.5554768371287366, 'repetition_penalty': 1.019349081907398, 'no_repeat_ngram_size': 2, 'max_new_tokens': 137}. Best is trial 10 with value: 0.27932960893854747.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 10: score=0.2793, length=86, params: top_k=96, top_p=0.95, temp=0.56, rep_pen=1.02, no_rep_ngram=2, max_tokens=137\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 07:13:24,372] Trial 11 finished with value: 0.16149068322981366 and parameters: {'top_k': 99, 'top_p': 0.9458934118113992, 'temperature': 0.5342946308193555, 'repetition_penalty': 1.0880119412761964, 'no_repeat_ngram_size': 2, 'max_new_tokens': 128}. Best is trial 10 with value: 0.27932960893854747.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 11: score=0.1615, length=74, params: top_k=99, top_p=0.95, temp=0.53, rep_pen=1.09, no_rep_ngram=2, max_tokens=128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 07:13:29,008] Trial 12 finished with value: 0.358695652173913 and parameters: {'top_k': 98, 'top_p': 0.9425853226859308, 'temperature': 0.5176776992651415, 'repetition_penalty': 1.0180368146560737, 'no_repeat_ngram_size': 2, 'max_new_tokens': 129}. Best is trial 12 with value: 0.358695652173913.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 12: score=0.3587, length=96, params: top_k=98, top_p=0.94, temp=0.52, rep_pen=1.02, no_rep_ngram=2, max_tokens=129\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 07:13:33,630] Trial 13 finished with value: 0.30000000000000004 and parameters: {'top_k': 99, 'top_p': 0.8793759723347118, 'temperature': 0.509327497528851, 'repetition_penalty': 1.018014647205958, 'no_repeat_ngram_size': 2, 'max_new_tokens': 129}. Best is trial 12 with value: 0.358695652173913.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 13: score=0.3000, length=93, params: top_k=99, top_p=0.88, temp=0.51, rep_pen=1.02, no_rep_ngram=2, max_tokens=129\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 07:13:39,426] Trial 14 finished with value: 0.19889502762430936 and parameters: {'top_k': 84, 'top_p': 0.876239818347908, 'temperature': 0.7595142482842471, 'repetition_penalty': 1.2180688122281913, 'no_repeat_ngram_size': 3, 'max_new_tokens': 155}. Best is trial 12 with value: 0.358695652173913.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 14: score=0.1989, length=84, params: top_k=84, top_p=0.88, temp=0.76, rep_pen=1.22, no_rep_ngram=3, max_tokens=155\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 07:13:44,059] Trial 15 finished with value: 0.24719101123595508 and parameters: {'top_k': 86, 'top_p': 0.8829833959782672, 'temperature': 0.5108221688262243, 'repetition_penalty': 1.202653583269648, 'no_repeat_ngram_size': 5, 'max_new_tokens': 128}. Best is trial 12 with value: 0.358695652173913.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 15: score=0.2472, length=82, params: top_k=86, top_p=0.88, temp=0.51, rep_pen=1.20, no_rep_ngram=5, max_tokens=128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 07:13:51,777] Trial 16 finished with value: -0.19092511013215857 and parameters: {'top_k': 88, 'top_p': 0.8624769053976025, 'temperature': 1.0599374743588286, 'repetition_penalty': 1.4482570880897228, 'no_repeat_ngram_size': 2, 'max_new_tokens': 216}. Best is trial 12 with value: 0.358695652173913.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 16: score=-0.1909, length=131, params: top_k=88, top_p=0.86, temp=1.06, rep_pen=1.45, no_rep_ngram=2, max_tokens=216\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 07:13:57,927] Trial 17 finished with value: -0.19636363636363635 and parameters: {'top_k': 57, 'top_p': 0.9096855700056012, 'temperature': 0.5064263967633732, 'repetition_penalty': 1.2298622136919688, 'no_repeat_ngram_size': 3, 'max_new_tokens': 172}. Best is trial 12 with value: 0.358695652173913.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 17: score=-0.1964, length=132, params: top_k=57, top_p=0.91, temp=0.51, rep_pen=1.23, no_rep_ngram=3, max_tokens=172\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 07:14:03,252] Trial 18 finished with value: 0.26851063829787236 and parameters: {'top_k': 93, 'top_p': 0.835670247884545, 'temperature': 0.7291077329798742, 'repetition_penalty': 1.0078964118080158, 'no_repeat_ngram_size': 2, 'max_new_tokens': 146}. Best is trial 12 with value: 0.358695652173913.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 18: score=0.2685, length=99, params: top_k=93, top_p=0.84, temp=0.73, rep_pen=1.01, no_rep_ngram=2, max_tokens=146\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-28 07:14:08,677] Trial 19 finished with value: 0.15819209039548024 and parameters: {'top_k': 83, 'top_p': 0.6806388066006412, 'temperature': 0.6157865495104835, 'repetition_penalty': 1.3391549552949282, 'no_repeat_ngram_size': 3, 'max_new_tokens': 147}. Best is trial 12 with value: 0.358695652173913.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 19: score=0.1582, length=88, params: top_k=83, top_p=0.68, temp=0.62, rep_pen=1.34, no_rep_ngram=3, max_tokens=147\n",
            "Best hyperparameters found: {'top_k': 98, 'top_p': 0.9425853226859308, 'temperature': 0.5176776992651415, 'repetition_penalty': 1.0180368146560737, 'no_repeat_ngram_size': 2, 'max_new_tokens': 129}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Disable TorchDynamo completely before importing torch\n",
        "os.environ[\"TORCH_COMPILE\"] = \"0\"\n",
        "os.environ[\"TORCHDYNAMO_DISABLE\"] = \"1\"\n",
        "os.environ[\"TORCH_INDUCTOR_DISABLED\"] = \"1\"\n",
        "\n",
        "import torch\n",
        "import torch._dynamo\n",
        "# Also suppress errors (as a fallback)\n",
        "torch._dynamo.config.suppress_errors = True\n",
        "\n",
        "import re\n",
        "import optuna\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "# -------------------------------\n",
        "# Load model and tokenizer\n",
        "# -------------------------------\n",
        "model_name = \"coderop12/Empowering_Legal_Summarization\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "if torch.cuda.is_available():\n",
        "    model.to(\"cuda\")\n",
        "print(\"✅ Model and tokenizer loaded successfully.\")\n",
        "\n",
        "# -------------------------------\n",
        "# Define generation function (runs in eager mode)\n",
        "# -------------------------------\n",
        "def generate_summary_custom(input_text, model, tokenizer,\n",
        "                            top_k, top_p, temperature, repetition_penalty, no_repeat_ngram_size, max_new_tokens=256):\n",
        "    prompt = (\n",
        "        \"Below is a legal document. Summarize its key points concisely.\\n\\n\"\n",
        "        \"### Document:\\n{input_text}\\n\\n### Summary:\"\n",
        "    )\n",
        "    # Limit input text length to avoid exceeding model limits.\n",
        "    input_str = prompt.format(input_text=input_text[:4096])\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model_inputs = tokenizer(\n",
        "        input_str,\n",
        "        return_tensors='pt',\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=4096\n",
        "    ).to(device)\n",
        "    \n",
        "    summary_ids = model.generate(\n",
        "        model_inputs.input_ids,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=True,\n",
        "        top_k=top_k,\n",
        "        top_p=top_p,\n",
        "        temperature=temperature,\n",
        "        repetition_penalty=repetition_penalty,\n",
        "        no_repeat_ngram_size=no_repeat_ngram_size\n",
        "    )\n",
        "    \n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    marker = \"### Summary:\"\n",
        "    if marker in summary:\n",
        "        summary = summary.split(marker, 1)[1].strip()\n",
        "    return summary\n",
        "\n",
        "# -------------------------------\n",
        "# Define evaluation function using ROUGE-1 F1 and a length penalty\n",
        "# -------------------------------\n",
        "def evaluate_summary(generated, reference, target_length=100):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
        "    scores = scorer.score(reference, generated)\n",
        "    rouge1_f1 = scores['rouge1'].fmeasure\n",
        "    \n",
        "    # Apply a penalty if the generated summary exceeds target_length words\n",
        "    generated_length = len(re.findall(r'\\w+', generated))\n",
        "    penalty = 0.0\n",
        "    if generated_length > target_length:\n",
        "        penalty = 0.01 * (generated_length - target_length)\n",
        "    \n",
        "    return rouge1_f1 - penalty\n",
        "\n",
        "# -------------------------------\n",
        "# Sample document and reference summary for tuning\n",
        "# -------------------------------\n",
        "sample_document = (\n",
        "    \"The court observed that the respondents are entitled to seek pre deposit of only 20% of the disputed demand subject to \"\n",
        "    \"fulfillment of W.P. (C) 14536 2021. The court observed, “The Court observed that in order to provide guidance and lay down \"\n",
        "    \"principles regarding stay of demand, the Central Board of Direct Taxes has issued various Circulars and Office Memorandums \"\n",
        "    \"dated 29th February 2016 and 31st July 2017 prescribing that in cases where an assessee challenges additions and disallowances...\"\n",
        ")\n",
        "\n",
        "reference_summary = (\n",
        "    \"The court held that respondents are entitled only to a pre-deposit of 20% of the disputed tax demand, provided that the petitioner receives \"\n",
        "    \"an opportunity for a pre-decisional hearing. Citing various circulars and office memorandums issued between February 2016 and July 2017, \"\n",
        "    \"the court emphasized that any refund adjustments beyond 20% must be returned until the first appeal is resolved. Assessing officers may \"\n",
        "    \"grant a stay on the recovery of the remaining demand and process manual refunds in line with ITBA instructions.\"\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# Define the objective function for hyperparameter tuning\n",
        "# -------------------------------\n",
        "def objective(trial):\n",
        "    # Sample hyperparameters\n",
        "    top_k = trial.suggest_int(\"top_k\", 20, 100)\n",
        "    top_p = trial.suggest_float(\"top_p\", 0.6, 0.95)\n",
        "    temperature = trial.suggest_float(\"temperature\", 0.5, 1.5, log=True)\n",
        "    repetition_penalty = trial.suggest_float(\"repetition_penalty\", 1.0, 2.0)\n",
        "    no_repeat_ngram_size = trial.suggest_int(\"no_repeat_ngram_size\", 2, 5)\n",
        "    max_new_tokens = trial.suggest_int(\"max_new_tokens\", 128, 256)\n",
        "    \n",
        "    # Generate the summary\n",
        "    summary = generate_summary_custom(\n",
        "        sample_document, model, tokenizer,\n",
        "        top_k=top_k,\n",
        "        top_p=top_p,\n",
        "        temperature=temperature,\n",
        "        repetition_penalty=repetition_penalty,\n",
        "        no_repeat_ngram_size=no_repeat_ngram_size,\n",
        "        max_new_tokens=max_new_tokens\n",
        "    )\n",
        "    \n",
        "    # Evaluate the summary using ROUGE-1 F1 with a length penalty\n",
        "    score = evaluate_summary(summary, reference_summary, target_length=100)\n",
        "    \n",
        "    print(f\"Trial {trial.number}: score={score:.4f}, length={len(summary.split())}, \"\n",
        "          f\"params: top_k={top_k}, top_p={top_p:.2f}, temp={temperature:.2f}, rep_pen={repetition_penalty:.2f}, \"\n",
        "          f\"no_rep_ngram={no_repeat_ngram_size}, max_tokens={max_new_tokens}\")\n",
        "    \n",
        "    return score\n",
        "\n",
        "# -------------------------------\n",
        "# Run hyperparameter tuning with Optuna\n",
        "# -------------------------------\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "print(\"Best hyperparameters found:\", study.best_trial.params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-02-28 07:20:41.049 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 07:20:41.070 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
            "2025-02-28 07:20:41.071 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 07:20:41.071 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 07:20:41.072 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 07:20:41.072 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 07:20:41.073 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 07:20:41.073 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 07:20:41.074 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-02-28 07:20:42.154 Thread 'Thread-5': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 07:20:42.154 Thread 'Thread-6': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 07:20:42.158 Thread 'Thread-5': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 07:20:42.160 Thread 'Thread-6': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "266c816589a846a39a5f1e7ca43cd032",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-02-28 07:20:43.893 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 07:20:43.894 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 07:20:43.894 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 07:20:43.895 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 07:20:43.895 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 07:20:43.895 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 07:20:43.952 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 07:20:43.954 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 07:20:43.956 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 07:20:43.957 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 07:20:43.957 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import fitz  # PyMuPDF\n",
        "import re\n",
        "import torch\n",
        "\n",
        "# Function to sanitize text by removing illegal characters\n",
        "def sanitize_text(text):\n",
        "    return re.sub(r'[\\x00-\\x1F\\x7F-\\x9F]', '', text)\n",
        "\n",
        "# Function to remove duplicate sentences\n",
        "def remove_duplicate_sentences(text):\n",
        "    sentences = text.split('. ')\n",
        "    unique_sentences = list(dict.fromkeys(sentences))  # Preserve order and remove duplicates\n",
        "    return '. '.join(unique_sentences)\n",
        "\n",
        "# Function to load the model and tokenizer\n",
        "@st.cache_resource\n",
        "def load_model_and_tokenizer(model_name):\n",
        "    try:\n",
        "        with st.spinner(\"Loading model and tokenizer...\"):\n",
        "            tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                model_name, \n",
        "                torch_dtype=torch.float16,  # Load in fp16 for efficiency\n",
        "                device_map=\"auto\"  # Automatically use GPU if available\n",
        "            )\n",
        "            if torch.cuda.is_available():\n",
        "                model.to(\"cuda\")\n",
        "            st.success(\"✅ Model loaded successfully.\")\n",
        "            return model, tokenizer\n",
        "    except Exception as e:\n",
        "        st.error(f\"❌ Error loading model/tokenizer: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Function to extract text from a PDF file\n",
        "def extract_text_from_pdf(uploaded_file):\n",
        "    text = \"\"\n",
        "    try:\n",
        "        pdf_document = fitz.open(stream=uploaded_file.read(), filetype=\"pdf\")\n",
        "        for page in pdf_document:\n",
        "            text += page.get_text() or \"\"\n",
        "        pdf_document.close()\n",
        "    except Exception as e:\n",
        "        st.error(f\"❌ Error extracting text from PDF: {e}\")\n",
        "    return text.strip()\n",
        "\n",
        "# Function to chunk the input text\n",
        "def chunk_text(text, max_length=2000):\n",
        "    # Split the text into chunks of max_length\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    for word in words:\n",
        "        current_chunk.append(word)\n",
        "        if len(' '.join(current_chunk)) >= max_length:\n",
        "            chunks.append(' '.join(current_chunk))\n",
        "            current_chunk = []\n",
        "    if current_chunk:\n",
        "        chunks.append(' '.join(current_chunk))\n",
        "    return chunks\n",
        "\n",
        "# Updated function to generate a summary using the tuned hyperparameters\n",
        "def generate_summary(input_text, model, tokenizer):\n",
        "    try:\n",
        "        prompt = (\n",
        "            \"Below is a legal document. Summarize its key points concisely.\\n\\n\"\n",
        "            \"### Document:\\n{input_text}\\n\\n### Summary:\"\n",
        "        )\n",
        "        # Use only the first 4096 characters from the chunk\n",
        "        input_str = prompt.format(input_text=input_text[:4096])\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        model_inputs = tokenizer(\n",
        "            input_str,\n",
        "            return_tensors='pt',\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=4096\n",
        "        ).to(device)\n",
        "\n",
        "        # Use tuned generation parameters\n",
        "        summary_output = model.generate(\n",
        "            model_inputs.input_ids,\n",
        "            max_new_tokens=129,\n",
        "            do_sample=True,\n",
        "            top_k=98,\n",
        "            top_p=0.9426,\n",
        "            temperature=0.5177,\n",
        "            repetition_penalty=1.0180,\n",
        "            no_repeat_ngram_size=2\n",
        "        )\n",
        "\n",
        "        full_output = tokenizer.decode(summary_output[0], skip_special_tokens=True)\n",
        "        marker = \"### Summary:\"\n",
        "        summary = full_output.split(marker, 1)[1].strip() if marker in full_output else full_output.strip()\n",
        "        return sanitize_text(summary)\n",
        "    except Exception as e:\n",
        "        st.error(f\"❌ Error generating summary: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Streamlit interface\n",
        "st.title(\"Legal Case Summary Generator\")\n",
        "\n",
        "# Update the model name to use the tuned repository\n",
        "model_name = \"coderop12/Empowering_Legal_Summarization\"\n",
        "model, tokenizer = load_model_and_tokenizer(model_name)\n",
        "\n",
        "# File upload\n",
        "uploaded_file = st.file_uploader(\"Upload a case PDF file\", type=[\"pdf\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    case_text = extract_text_from_pdf(uploaded_file)\n",
        "    \n",
        "    st.subheader(\"Original Case Text\")\n",
        "    st.write(case_text)\n",
        "\n",
        "    if st.button(\"Generate Summary\"):\n",
        "        if model is not None and tokenizer is not None:\n",
        "            sanitized_text = sanitize_text(case_text)\n",
        "            unique_text = remove_duplicate_sentences(sanitized_text)\n",
        "            chunks = chunk_text(unique_text)\n",
        "\n",
        "            # Generate summaries for each chunk using the tuned settings\n",
        "            summaries = []\n",
        "            for chunk in chunks:\n",
        "                summary = generate_summary(chunk, model, tokenizer)\n",
        "                summaries.append(summary)\n",
        "\n",
        "            # Combine the summaries\n",
        "            final_summary = \"\\n\".join(summaries)\n",
        "            sanitized_final_summary = sanitize_text(final_summary)\n",
        "            st.subheader(\"Generated Summary\")\n",
        "            st.write(sanitized_final_summary)\n",
        "        else:\n",
        "            st.error(\"Model or tokenizer not loaded properly.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Usage: streamlit run [OPTIONS] TARGET [ARGS]...\n",
            "Try 'streamlit run --help' for help.\n",
            "\n",
            "Error: Invalid value: File does not exist: app.py\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: streamlit in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.42.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from streamlit) (5.5.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from streamlit) (2.1.4)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from streamlit) (4.23.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from streamlit) (19.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (1.28.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (2.19.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: tools in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.1.9)\n",
            "Requirement already satisfied: pytils in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tools) (0.4.1)\n",
            "Requirement already satisfied: six in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tools) (1.17.0)\n",
            "Requirement already satisfied: lxml in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tools) (5.3.1)\n",
            "Collecting fitz\n",
            "  Downloading fitz-0.0.1.dev2-py2.py3-none-any.whl.metadata (816 bytes)\n",
            "Collecting configobj (from fitz)\n",
            "  Downloading configobj-5.0.9-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting configparser (from fitz)\n",
            "  Downloading configparser-7.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting httplib2 (from fitz)\n",
            "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting nibabel (from fitz)\n",
            "  Downloading nibabel-5.3.2-py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting nipype (from fitz)\n",
            "  Downloading nipype-1.9.2-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fitz) (1.26.4)\n",
            "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fitz) (2.1.4)\n",
            "Collecting pyxnat (from fitz)\n",
            "  Downloading pyxnat-1.6.3-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: scipy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fitz) (1.11.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from httplib2->fitz) (3.2.1)\n",
            "Collecting importlib-resources>=5.12 (from nibabel->fitz)\n",
            "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: packaging>=20 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nibabel->fitz) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nibabel->fitz) (4.12.2)\n",
            "Requirement already satisfied: click>=6.6.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nipype->fitz) (8.1.8)\n",
            "Requirement already satisfied: networkx>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nipype->fitz) (3.4.2)\n",
            "Collecting prov>=1.5.2 (from nipype->fitz)\n",
            "  Downloading prov-2.0.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting pydot>=1.2.3 (from nipype->fitz)\n",
            "  Downloading pydot-3.0.4-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nipype->fitz) (2.9.0.post0)\n",
            "Collecting rdflib>=5.0.0 (from nipype->fitz)\n",
            "  Downloading rdflib-7.1.3-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting simplejson>=3.8.0 (from nipype->fitz)\n",
            "  Downloading simplejson-3.20.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting traits>=6.2 (from nipype->fitz)\n",
            "  Downloading traits-7.0.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: filelock>=3.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nipype->fitz) (3.17.0)\n",
            "Collecting acres (from nipype->fitz)\n",
            "  Downloading acres-0.3.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting etelemetry>=0.3.1 (from nipype->fitz)\n",
            "  Downloading etelemetry-0.3.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting looseversion!=1.2 (from nipype->fitz)\n",
            "  Downloading looseversion-1.3.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting puremagic (from nipype->fitz)\n",
            "  Downloading puremagic-1.28-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->fitz) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->fitz) (2025.1)\n",
            "Requirement already satisfied: lxml>=4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pyxnat->fitz) (5.3.1)\n",
            "Requirement already satisfied: requests>=2.20 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pyxnat->fitz) (2.32.3)\n",
            "Collecting pathlib>=1.0 (from pyxnat->fitz)\n",
            "  Downloading pathlib-1.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting ci-info>=0.2 (from etelemetry>=0.3.1->nipype->fitz)\n",
            "  Downloading ci_info-0.3.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting rdflib>=5.0.0 (from nipype->fitz)\n",
            "  Downloading rdflib-6.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.2->nipype->fitz) (1.17.0)\n",
            "Collecting isodate<0.7.0,>=0.6.0 (from rdflib>=5.0.0->nipype->fitz)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.20->pyxnat->fitz) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.20->pyxnat->fitz) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.20->pyxnat->fitz) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.20->pyxnat->fitz) (2025.1.31)\n",
            "Downloading fitz-0.0.1.dev2-py2.py3-none-any.whl (20 kB)\n",
            "Downloading configobj-5.0.9-py2.py3-none-any.whl (35 kB)\n",
            "Downloading configparser-7.1.0-py3-none-any.whl (17 kB)\n",
            "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
            "Downloading nibabel-5.3.2-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m185.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nipype-1.9.2-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m191.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyxnat-1.6.3-py3-none-any.whl (95 kB)\n",
            "Downloading etelemetry-0.3.1-py3-none-any.whl (6.4 kB)\n",
            "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
            "Downloading looseversion-1.3.0-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading pathlib-1.0.1-py3-none-any.whl (14 kB)\n",
            "Downloading prov-2.0.1-py3-none-any.whl (421 kB)\n",
            "Downloading pydot-3.0.4-py3-none-any.whl (35 kB)\n",
            "Downloading rdflib-6.3.2-py3-none-any.whl (528 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m528.1/528.1 kB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading simplejson-3.20.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "Downloading traits-7.0.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m192.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading acres-0.3.0-py3-none-any.whl (10 kB)\n",
            "Downloading puremagic-1.28-py3-none-any.whl (43 kB)\n",
            "Downloading ci_info-0.3.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "Installing collected packages: puremagic, pathlib, looseversion, traits, simplejson, pydot, isodate, importlib-resources, httplib2, configparser, configobj, ci-info, rdflib, pyxnat, nibabel, etelemetry, acres, prov, nipype, fitz\n",
            "Successfully installed acres-0.3.0 ci-info-0.3.0 configobj-5.0.9 configparser-7.1.0 etelemetry-0.3.1 fitz-0.0.1.dev2 httplib2-0.22.0 importlib-resources-6.5.2 isodate-0.6.1 looseversion-1.3.0 nibabel-5.3.2 nipype-1.9.2 pathlib-1.0.1 prov-2.0.1 puremagic-1.28 pydot-3.0.4 pyxnat-1.6.3 rdflib-6.3.2 simplejson-3.20.1 traits-7.0.2\n",
            "Requirement already satisfied: frontend in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.0.3)\n",
            "Requirement already satisfied: starlette>=0.12.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from frontend) (0.45.3)\n",
            "Requirement already satisfied: uvicorn>=0.7.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from frontend) (0.34.0)\n",
            "Requirement already satisfied: itsdangerous>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from frontend) (2.2.0)\n",
            "Requirement already satisfied: aiofiles in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from frontend) (24.1.0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from starlette>=0.12.0->frontend) (4.8.0)\n",
            "Requirement already satisfied: click>=7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from uvicorn>=0.7.1->frontend) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from uvicorn>=0.7.1->frontend) (0.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from uvicorn>=0.7.1->frontend) (4.12.2)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette>=0.12.0->frontend) (1.2.2)\n",
            "Requirement already satisfied: idna>=2.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette>=0.12.0->frontend) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette>=0.12.0->frontend) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit\n",
        "!pip install tools\n",
        "!pip install fitz\n",
        "!pip install frontend"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0569b998791d419a88aa1fb8236f7edf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05fafc57d2df4b8eaf55c9c3c4c6ae68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8235bece0b374394911b7cdcefdd6069",
            "placeholder": "​",
            "style": "IPY_MODEL_c275e418600540d0889684476cbd7f10",
            "value": " 47.0k/47.0k [00:00&lt;00:00, 2.69MB/s]"
          }
        },
        "065716abe11c489ba9f99538d7f4aa92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08498f1924b24a56883204d3ac3462ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09454937d0f34dae90863559dad242c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a8ed977bbc04adf9de698259ff04120": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fb377025abe4cfcaae0b5b3fbef9c5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6259c70435a843d0afcc4f8de6b62423",
            "max": 1015,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8bdbee54e69641be8279af18db853969",
            "value": 1015
          }
        },
        "1022ab469cd8457cbda4c3ba75938ef2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "105423f09e104b469b66f5a920ab224d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "105772994f384981944e6cd47bc454c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "111ae0b8e63f472cb93f15d484d47489": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17997cc9291c4b958e89f107705c5eb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "183b2ed298f144d18cde7b68c1c7ef09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ced80a1efff4871b368bcdf2878ab7e",
            "max": 187,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f10f1b8aa5914ff4a5d5b20ba63c92d5",
            "value": 187
          }
        },
        "1b6a32a861ba47aa8c2b0421d7446e38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c2e8439bb14496691c12418f1267d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_657254ed1061495d9eff75585e50e3a0",
            "placeholder": "​",
            "style": "IPY_MODEL_c820ba86d9ce42f4ba1051c5ed0982d3",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "1de3612e9cd0471a9d4b7a97d7f67382": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20aa326f75aa4a76af3f64e2000faa11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a8ed977bbc04adf9de698259ff04120",
            "placeholder": "​",
            "style": "IPY_MODEL_9b117ebbcbc34926a60491037735848d",
            "value": "Map: 100%"
          }
        },
        "22d9952d76f54e4b98c000d983fa9c2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2366ed8a1480413cb095436f13a67d4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cf13ca9928b41edb5bbdc55aa8827bf",
            "placeholder": "​",
            "style": "IPY_MODEL_4cb0fa6886c049b289ed10b32453b1cd",
            "value": "Downloading shards: 100%"
          }
        },
        "253d2ef1db514fec9ddc423f294e460b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25bfac9a2c054bdf8d449b815c1e1b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27cad37233f44d59bf75463ab551899d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d52c961e1a7f48ebb67eaa5b9bcc5300",
            "placeholder": "​",
            "style": "IPY_MODEL_f606b15090b447a6b6fbd61481dd8624",
            "value": "config.json: 100%"
          }
        },
        "2a096308a7924d6b9b61a2535839f309": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2366ed8a1480413cb095436f13a67d4e",
              "IPY_MODEL_a475e49f89cc4478966147d12b15e7e2",
              "IPY_MODEL_e8d073df6f8742e18d2fd22d9ab3967a"
            ],
            "layout": "IPY_MODEL_e22a05323e0740ef93cb39a3ee84ed9c"
          }
        },
        "2a6f2cc06b2e4817a17873da1f6340a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e3782e3683c49b7acf088922f9f7efe",
            "placeholder": "​",
            "style": "IPY_MODEL_9d6d9f0acbf645a4af5c5d2f6cce730a",
            "value": " 636/636 [00:00&lt;00:00, 50.0kB/s]"
          }
        },
        "2c8041c25f1d49ff965957cb471905d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d7e4da78dbf4138b68df674e83c3f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc6e43f233c6447a9b84f70925380a6f",
            "placeholder": "​",
            "style": "IPY_MODEL_8e752803389342488471c92471e23c32",
            "value": "Filter: 100%"
          }
        },
        "3408a6c94eb84f85bd85817e66516bc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79e025fc8e6444c398bd632b56458cab",
            "max": 838,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_622f56aa5cc84b6889107df01e6b30bf",
            "value": 838
          }
        },
        "34f616e54ec8488499586bbc7f34960b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "366e3a590dbc43f082dc52855ff6ba9b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ad3a3a5b67348cd93ff94d6363ada9d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3cb5750426cf42f4a405bcccf1e75c60": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3edb862a93a74509a393fa2d1bc81745": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f23a82e950a4ba9849644666eb1de44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40260f3b152d4fb6baab27715bf38d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45ddfa77ba844cdc9f6c3a2bd9f58c0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9902700ef0e45a3968711d784553f40",
              "IPY_MODEL_7115888a87c2489b9e57e413013f4088",
              "IPY_MODEL_05fafc57d2df4b8eaf55c9c3c4c6ae68"
            ],
            "layout": "IPY_MODEL_a016c67c66ba4dc09519dbc1444e63cd"
          }
        },
        "4a32550a19544b238fe4d629321a81ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b55c63eca5a47d7bb8021350e95535f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cb0fa6886c049b289ed10b32453b1cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d0198ff6abb43beb9ddbd3ce9063d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67e37c4608af4443adf51ca2dda763c3",
            "placeholder": "​",
            "style": "IPY_MODEL_de8e236876ca4deb94f1e722c9cefaa6",
            "value": " 1015/1015 [00:00&lt;00:00, 6415.21 examples/s]"
          }
        },
        "4d8f3e697d3f4cfd814cfda0890fa1f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20aa326f75aa4a76af3f64e2000faa11",
              "IPY_MODEL_a5310ad5f3cf460485e4bc4a8f3ad845",
              "IPY_MODEL_bd81385d5ba84c8fbeb39305c34f5785"
            ],
            "layout": "IPY_MODEL_b9dd980e52cf48caba45a8d228de34ea"
          }
        },
        "4dc7dc4eaf72438696873714f8340306": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ec685ac30134eb9acf6608b2a5d48f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b6a32a861ba47aa8c2b0421d7446e38",
            "max": 4241003,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96c08135ed0a4074a9f7611b7025f93d",
            "value": 4241003
          }
        },
        "5274e3c16d114f0ea50ccca2d76406f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27cad37233f44d59bf75463ab551899d",
              "IPY_MODEL_3408a6c94eb84f85bd85817e66516bc2",
              "IPY_MODEL_6838b3e2adac4f529358a43d9a8b7740"
            ],
            "layout": "IPY_MODEL_c6f5164cbf0a48ff89857b3d7a92e73d"
          }
        },
        "54b82396fd0347818244611aaa816910": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c32a8c1174f74eb48e9250d93f35d321",
            "placeholder": "​",
            "style": "IPY_MODEL_c5f9a31e342a426389bd97e4f485732a",
            "value": " 2/2 [00:29&lt;00:00, 12.50s/it]"
          }
        },
        "5511ca8c1f8741b88c76c812a69f7b74": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cf13ca9928b41edb5bbdc55aa8827bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d3d5c6c580d4b8a9ff54951c663db31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5dd73d5e751b4d479b3449214a2c0d6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c2e8439bb14496691c12418f1267d32",
              "IPY_MODEL_ef86898a02f84071970030d7b1d54c1e",
              "IPY_MODEL_54b82396fd0347818244611aaa816910"
            ],
            "layout": "IPY_MODEL_d6d84ab8df6847ea931ca6c895aeaa82"
          }
        },
        "5e3782e3683c49b7acf088922f9f7efe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "622f56aa5cc84b6889107df01e6b30bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6259c70435a843d0afcc4f8de6b62423": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "657254ed1061495d9eff75585e50e3a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67e37c4608af4443adf51ca2dda763c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6838b3e2adac4f529358a43d9a8b7740": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_815c373fc8284224abf399b8b0099b20",
            "placeholder": "​",
            "style": "IPY_MODEL_e58fa949ba2a43c88f26bf97b47231b1",
            "value": " 838/838 [00:00&lt;00:00, 29.1kB/s]"
          }
        },
        "6be94c113df142eeaf65577ffa14d302": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c7cc831d4b043eeb786daee5f06e570": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e12ca76e414347adac47597d86d78129",
            "placeholder": "​",
            "style": "IPY_MODEL_a82a861ee41744079a5d9fb3cc0e6b25",
            "value": " 17.5M/17.5M [00:00&lt;00:00, 43.1MB/s]"
          }
        },
        "6cf4fdb1a8324b32a043044902955d7c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d46d160a07348d9890581b8cfcc706d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22d9952d76f54e4b98c000d983fa9c2b",
            "placeholder": "​",
            "style": "IPY_MODEL_80eca95c72f14a8190520f6c19558b8c",
            "value": " 1015/1015 [00:06&lt;00:00, 159.64 examples/s]"
          }
        },
        "6edcc0fd6ea2496cb208df9a0a16d06a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6d4ca1d68f846a6bc310a5f23adbccb",
              "IPY_MODEL_bf8119cfb53546b0be17e9b06e973322",
              "IPY_MODEL_4d0198ff6abb43beb9ddbd3ce9063d1f"
            ],
            "layout": "IPY_MODEL_a00b20c75e8e4eef8ed06c624ec5509b"
          }
        },
        "6f632bc1d7644536a454ef1c471ea72a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7115888a87c2489b9e57e413013f4088": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1de3612e9cd0471a9d4b7a97d7f67382",
            "max": 46996,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f23a82e950a4ba9849644666eb1de44",
            "value": 46996
          }
        },
        "72ee8128268c4241a6f84ec4b2c32837": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7414aebf6f0342dfaaa53e4d3dd45d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74abbe6ca05349b8a29bdf76f0337dc6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74d0b880f9e04102ab38e95ce66a4886": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75d04fbf74d143ebb62efb889ecb0995": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76669936c01d455e86749c020b9c5f40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78fad996692c47fe9731405fd0247ae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1022ab469cd8457cbda4c3ba75938ef2",
            "max": 240691728,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09454937d0f34dae90863559dad242c6",
            "value": 240691728
          }
        },
        "79e025fc8e6444c398bd632b56458cab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b44a3cb7f7542b7894d7cffd678be13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de41f1ce52404698b701a19643bacd1e",
              "IPY_MODEL_fd17e394b34b48bfbfe74fc15b967e8a",
              "IPY_MODEL_da2d0880d9bd479994381c32b3f33feb"
            ],
            "layout": "IPY_MODEL_f1a4aca5f1ae40a08ab4e392cffcdf22"
          }
        },
        "7ce437ccd7fa4eb78ba1c7f49983bb92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ad3a3a5b67348cd93ff94d6363ada9d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6be94c113df142eeaf65577ffa14d302",
            "value": 1
          }
        },
        "7de1abc17a90492d8198821848627f74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75d04fbf74d143ebb62efb889ecb0995",
            "placeholder": "​",
            "style": "IPY_MODEL_3edb862a93a74509a393fa2d1bc81745",
            "value": "Generating train split: "
          }
        },
        "7f412a4c0e7444b09b06dca9cd897e97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fd24ef4645b40f38841668a6f52a4d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d19fb944aa734c1a9d978c7a8f8697c9",
              "IPY_MODEL_183b2ed298f144d18cde7b68c1c7ef09",
              "IPY_MODEL_c329802d6a904892b21875fa574b0af2"
            ],
            "layout": "IPY_MODEL_a834087dc73444fd85ee32c1b5aae5e8"
          }
        },
        "80eca95c72f14a8190520f6c19558b8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "815c373fc8284224abf399b8b0099b20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "821a39d28a2645a49288084b806e8779": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8235bece0b374394911b7cdcefdd6069": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "825760d4d3cc40fda33d6d263366b886": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82eb5bba126243ffa959d54580b157bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "851adcdf8cad4e908532cd0b4a33297f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b55c63eca5a47d7bb8021350e95535f",
            "placeholder": "​",
            "style": "IPY_MODEL_a016c37949844acea161cf325be0edec",
            "value": " 24.2k/24.2k [00:00&lt;00:00, 773kB/s]"
          }
        },
        "8b6be3a7608743e19d4815dfbaf7d32e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bdbee54e69641be8279af18db853969": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8dc128a5772943c498434ea6ec29dd24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d7e4da78dbf4138b68df674e83c3f0a",
              "IPY_MODEL_0fb377025abe4cfcaae0b5b3fbef9c5f",
              "IPY_MODEL_6d46d160a07348d9890581b8cfcc706d"
            ],
            "layout": "IPY_MODEL_fb56b601efdb4904891d26a1d835051b"
          }
        },
        "8e752803389342488471c92471e23c32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95e2441a15584cd9bbc951a3f35e8c66": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95e3e5a5e25b43d8aa433f24ea37619a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9664bb14307c4eb9b80de16d672c4f65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96c08135ed0a4074a9f7611b7025f93d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98d5e61919e54f578f2dc4023335c5cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a072d29996c44a9b5c323f09206a405": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f70e3c23129f4515a48ee1712f3da70b",
              "IPY_MODEL_c4a971659af54d26b90756601fcf0e5d",
              "IPY_MODEL_851adcdf8cad4e908532cd0b4a33297f"
            ],
            "layout": "IPY_MODEL_bb5d180413914ff2b051d2bb4f838e10"
          }
        },
        "9b117ebbcbc34926a60491037735848d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ced80a1efff4871b368bcdf2878ab7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d489b023b214eec8d97e5387b521199": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_105423f09e104b469b66f5a920ab224d",
            "placeholder": "​",
            "style": "IPY_MODEL_17997cc9291c4b958e89f107705c5eb3",
            "value": " 1015/0 [00:00&lt;00:00, 1132.63 examples/s]"
          }
        },
        "9d6d9f0acbf645a4af5c5d2f6cce730a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a00b20c75e8e4eef8ed06c624ec5509b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a016c37949844acea161cf325be0edec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a016c67c66ba4dc09519dbc1444e63cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a475e49f89cc4478966147d12b15e7e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f632bc1d7644536a454ef1c471ea72a",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_111ae0b8e63f472cb93f15d484d47489",
            "value": 2
          }
        },
        "a5310ad5f3cf460485e4bc4a8f3ad845": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74abbe6ca05349b8a29bdf76f0337dc6",
            "max": 1015,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72ee8128268c4241a6f84ec4b2c32837",
            "value": 1015
          }
        },
        "a7e0f7872bf640f88334dbbf0fb9cb4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7de1abc17a90492d8198821848627f74",
              "IPY_MODEL_7ce437ccd7fa4eb78ba1c7f49983bb92",
              "IPY_MODEL_9d489b023b214eec8d97e5387b521199"
            ],
            "layout": "IPY_MODEL_98d5e61919e54f578f2dc4023335c5cb"
          }
        },
        "a82a861ee41744079a5d9fb3cc0e6b25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a834087dc73444fd85ee32c1b5aae5e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9b8128f66fe4aa9a90824b9328c72e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b30ed3332c514972b385c5096cab961f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34f616e54ec8488499586bbc7f34960b",
            "placeholder": "​",
            "style": "IPY_MODEL_7f412a4c0e7444b09b06dca9cd897e97",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "b3ef3591e84743e292c0a1c9c0a5ea07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4a18682defd42e29ac036d754bf63c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9902700ef0e45a3968711d784553f40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebb71fdd59844154af88a5f7d06bcb39",
            "placeholder": "​",
            "style": "IPY_MODEL_bbfa52a3a69542e2a6a76de7edb2f3dd",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b9dd980e52cf48caba45a8d228de34ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb5d180413914ff2b051d2bb4f838e10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbfa52a3a69542e2a6a76de7edb2f3dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd81385d5ba84c8fbeb39305c34f5785": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_821a39d28a2645a49288084b806e8779",
            "placeholder": "​",
            "style": "IPY_MODEL_7414aebf6f0342dfaaa53e4d3dd45d98",
            "value": " 1015/1015 [00:08&lt;00:00, 123.32 examples/s]"
          }
        },
        "bf77e8d9ff6949f28587718c49b3a4dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf8119cfb53546b0be17e9b06e973322": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0569b998791d419a88aa1fb8236f7edf",
            "max": 1015,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_253d2ef1db514fec9ddc423f294e460b",
            "value": 1015
          }
        },
        "bf89f65111ea483f876b082d8cb82786": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c275e418600540d0889684476cbd7f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c329802d6a904892b21875fa574b0af2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa7414aac0c544d9bcf91c9db571309b",
            "placeholder": "​",
            "style": "IPY_MODEL_f8adbc24b704444e984a696173cc8ced",
            "value": " 187/187 [00:00&lt;00:00, 13.6kB/s]"
          }
        },
        "c32a8c1174f74eb48e9250d93f35d321": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c33c6a738f304b54abe4b00b81a426e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c83eb120c8ae4445934f862622f3658e",
              "IPY_MODEL_f82defedb9a84395aaa0490e4cb2b39b",
              "IPY_MODEL_6c7cc831d4b043eeb786daee5f06e570"
            ],
            "layout": "IPY_MODEL_f88676cc6cdd41d78757bd44dd5fac4e"
          }
        },
        "c4a971659af54d26b90756601fcf0e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_decf38b88f734a9f9ceb58ab42c7eed5",
            "max": 24223,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_daa350d8d4c14204813b4e4218e9cd5d",
            "value": 24223
          }
        },
        "c5f9a31e342a426389bd97e4f485732a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6f5164cbf0a48ff89857b3d7a92e73d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c820ba86d9ce42f4ba1051c5ed0982d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c83eb120c8ae4445934f862622f3658e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_105772994f384981944e6cd47bc454c0",
            "placeholder": "​",
            "style": "IPY_MODEL_f0328557549c4f4aba843e630c8e37c2",
            "value": "tokenizer.json: 100%"
          }
        },
        "c85e0f0918c04f25ad7e0000690f0ddb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca3c2ee25a1d4b07961b7b6e645b0924": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe19b4c27da24b63a08d8e30dcc4f8c2",
              "IPY_MODEL_4ec685ac30134eb9acf6608b2a5d48f6",
              "IPY_MODEL_d443808e423b4010ba30615a8c3b8730"
            ],
            "layout": "IPY_MODEL_e4f2e1ecf7b246559185ea9afa2bf96d"
          }
        },
        "cc6e43f233c6447a9b84f70925380a6f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d19fb944aa734c1a9d978c7a8f8697c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5511ca8c1f8741b88c76c812a69f7b74",
            "placeholder": "​",
            "style": "IPY_MODEL_76669936c01d455e86749c020b9c5f40",
            "value": "generation_config.json: 100%"
          }
        },
        "d2ec397860284fe2b77003aa0cc8ca08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d443808e423b4010ba30615a8c3b8730": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc17fe6575024facb15c05e157622b7e",
            "placeholder": "​",
            "style": "IPY_MODEL_5d3d5c6c580d4b8a9ff54951c663db31",
            "value": " 4.24M/4.24M [00:00&lt;00:00, 41.9MB/s]"
          }
        },
        "d4ce4d8312a1482ab3f12b4402a2d614": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b30ed3332c514972b385c5096cab961f",
              "IPY_MODEL_e1ab5a1d24b54fddaca57ca8b176f8d5",
              "IPY_MODEL_2a6f2cc06b2e4817a17873da1f6340a6"
            ],
            "layout": "IPY_MODEL_4a32550a19544b238fe4d629321a81ea"
          }
        },
        "d52c961e1a7f48ebb67eaa5b9bcc5300": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d69bf5645de24de68131a00fd3b1ea3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95e2441a15584cd9bbc951a3f35e8c66",
            "placeholder": "​",
            "style": "IPY_MODEL_f2db6890a0224ee1be8271e7de0198b1",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "d6d4ca1d68f846a6bc310a5f23adbccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cb5750426cf42f4a405bcccf1e75c60",
            "placeholder": "​",
            "style": "IPY_MODEL_8b6be3a7608743e19d4815dfbaf7d32e",
            "value": "Map: 100%"
          }
        },
        "d6d84ab8df6847ea931ca6c895aeaa82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9695c00c7d442d38bb26325d974350d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da2d0880d9bd479994381c32b3f33feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_366e3a590dbc43f082dc52855ff6ba9b",
            "placeholder": "​",
            "style": "IPY_MODEL_40260f3b152d4fb6baab27715bf38d3e",
            "value": " 4.99G/4.99G [01:58&lt;00:00, 42.3MB/s]"
          }
        },
        "daa350d8d4c14204813b4e4218e9cd5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc17fe6575024facb15c05e157622b7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de41f1ce52404698b701a19643bacd1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82eb5bba126243ffa959d54580b157bb",
            "placeholder": "​",
            "style": "IPY_MODEL_25bfac9a2c054bdf8d449b815c1e1b76",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "de8e236876ca4deb94f1e722c9cefaa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "decf38b88f734a9f9ceb58ab42c7eed5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e12ca76e414347adac47597d86d78129": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1ab5a1d24b54fddaca57ca8b176f8d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_065716abe11c489ba9f99538d7f4aa92",
            "max": 636,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9664bb14307c4eb9b80de16d672c4f65",
            "value": 636
          }
        },
        "e22a05323e0740ef93cb39a3ee84ed9c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2f5af3717f0403ba3011ed9a0c44df1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d69bf5645de24de68131a00fd3b1ea3e",
              "IPY_MODEL_78fad996692c47fe9731405fd0247ae2",
              "IPY_MODEL_f5e95f158c984620880f152122228041"
            ],
            "layout": "IPY_MODEL_74d0b880f9e04102ab38e95ce66a4886"
          }
        },
        "e4f2e1ecf7b246559185ea9afa2bf96d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e58fa949ba2a43c88f26bf97b47231b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8d073df6f8742e18d2fd22d9ab3967a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dc7dc4eaf72438696873714f8340306",
            "placeholder": "​",
            "style": "IPY_MODEL_a9b8128f66fe4aa9a90824b9328c72e8",
            "value": " 2/2 [02:04&lt;00:00, 52.34s/it]"
          }
        },
        "ebb71fdd59844154af88a5f7d06bcb39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef86898a02f84071970030d7b1d54c1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08498f1924b24a56883204d3ac3462ce",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf77e8d9ff6949f28587718c49b3a4dc",
            "value": 2
          }
        },
        "f0328557549c4f4aba843e630c8e37c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f10f1b8aa5914ff4a5d5b20ba63c92d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1a4aca5f1ae40a08ab4e392cffcdf22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2db6890a0224ee1be8271e7de0198b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5e95f158c984620880f152122228041": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c85e0f0918c04f25ad7e0000690f0ddb",
            "placeholder": "​",
            "style": "IPY_MODEL_2c8041c25f1d49ff965957cb471905d8",
            "value": " 241M/241M [00:05&lt;00:00, 42.2MB/s]"
          }
        },
        "f606b15090b447a6b6fbd61481dd8624": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f70e3c23129f4515a48ee1712f3da70b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cf4fdb1a8324b32a043044902955d7c",
            "placeholder": "​",
            "style": "IPY_MODEL_d9695c00c7d442d38bb26325d974350d",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "f82defedb9a84395aaa0490e4cb2b39b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2ec397860284fe2b77003aa0cc8ca08",
            "max": 17525357,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_825760d4d3cc40fda33d6d263366b886",
            "value": 17525357
          }
        },
        "f88676cc6cdd41d78757bd44dd5fac4e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8adbc24b704444e984a696173cc8ced": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa7414aac0c544d9bcf91c9db571309b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb56b601efdb4904891d26a1d835051b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd17e394b34b48bfbfe74fc15b967e8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95e3e5a5e25b43d8aa433f24ea37619a",
            "max": 4988025760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf89f65111ea483f876b082d8cb82786",
            "value": 4988025760
          }
        },
        "fe19b4c27da24b63a08d8e30dcc4f8c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4a18682defd42e29ac036d754bf63c1",
            "placeholder": "​",
            "style": "IPY_MODEL_b3ef3591e84743e292c0a1c9c0a5ea07",
            "value": "tokenizer.model: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
